{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation: we perform synonym and random\n",
    "word replacement with NLTK and WordNet on the contexts\n",
    "of the SQuAD dataset. Questions are left unchanged. We\n",
    "explored different strategies of synonym replacement\n",
    "(sampling rate, +random words, +stop words) and\n",
    "injected different amount of augmented data (x0.33, x1, x2,\n",
    "x3) on top of the original data in our experiments.\n",
    "● For each word in a context paragraph\n",
    "○ 20% of the time:\n",
    "call replace_synonym\n",
    "■ if exists synonyms:\n",
    "replace with a random synonym\n",
    "■ otherwise:\n",
    "replace with a random word\n",
    "○ 80% of the time: remain unchanged\n",
    "\n",
    "http://web.stanford.edu/class/cs224n/posters/15845024.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)  # suppress some deprecation warnings\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_directory = './data'\n",
    "\n",
    "data_val = pd.read_csv(os.path.join(data_directory, 'cloze_test_val__spring2016 - cloze_test_ALL_val.csv'), header='infer')\n",
    "data_test = pd.read_csv(os.path.join(data_directory, 'cloze_test_test__spring2016 - cloze_test_ALL_test.csv'), header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0601 09:57:54.969856 47083185057216 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cluster/home/sanagnos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /cluster/home/sanagnos/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /cluster/home/sanagnos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_val):\n",
    "    contexts = list()\n",
    "    last_sentences = list()\n",
    "    classes = list()\n",
    "    for pos in range(len(data_val)):\n",
    "        story_start = data_val.iloc[pos][['InputSentence' + str(i) for i in [1, 2, 3, 4]]].values\n",
    "        \n",
    "        contexts.append(\" \".join(story_start))\n",
    "        last_sentences.append(data_val.iloc[pos]['RandomFifthSentenceQuiz1'])\n",
    "        contexts.append(\" \".join(story_start))\n",
    "        last_sentences.append(data_val.iloc[pos]['RandomFifthSentenceQuiz2'])\n",
    "        \n",
    "        if data_val.iloc[pos]['AnswerRightEnding'] == 1:\n",
    "            classes.append(0)\n",
    "            classes.append(1)\n",
    "        else:\n",
    "            classes.append(1)\n",
    "            classes.append(0)\n",
    "            \n",
    "    return pd.DataFrame({'story': contexts, 'ending': last_sentences, 'class': classes})\n",
    "\n",
    "val_pd = create_dataset(data_val)\n",
    "test_pd = create_dataset(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3742\n",
      "3742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train = shuffle(val_pd)\n",
    "train_unshuffled = val_pd\n",
    "test = test_pd\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_COLUMN = 'story'\n",
    "ENDING_COLUMN = 'ending'\n",
    "LABEL_COLUMN = 'class'\n",
    "\n",
    "# label_list is 0 for a true story and 1 for a false story\n",
    "label_list = [0, 1]\n",
    "\n",
    "REPLICATION_FACTOR = 6\n",
    "\n",
    "\n",
    "train_InputExamples = pd.concat([train]*REPLICATION_FACTOR).apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
    "                                                                   text_a = x[CONTEXT_COLUMN], \n",
    "                                                                   text_b = x[ENDING_COLUMN], \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[CONTEXT_COLUMN], \n",
    "                                                                   text_b = x[ENDING_COLUMN], \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "# BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-24_H-1024_A-16/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "\n",
    "def replace_with_synonym(token, tokenizer):\n",
    "  new_token = token\n",
    "  synonyms = []\n",
    "  for syn in wordnet.synsets(token):\n",
    "    for l in syn.lemmas():\n",
    "      synonyms.append(l.name())\n",
    "  if len(synonyms) > 0:\n",
    "    new_token = tokenizer.tokenize(random.choice(synonyms))[0]\n",
    "#     print(token, new_token)\n",
    "  return new_token\n",
    "\n",
    "\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length,\n",
    "                                 tokenizer, set_synonyms=False, percentage_synonyms=0.2):\n",
    "  \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "  \n",
    "  if set_synonyms == False:\n",
    "    percentage_synonyms = 0\n",
    "\n",
    "  features = []\n",
    "  for (ex_index, example) in enumerate(examples):\n",
    "    if ex_index % 10000 == 0:\n",
    "      tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "\n",
    "    feature = convert_single_example(ex_index, example, label_list,\n",
    "                                     max_seq_length, tokenizer, percentage_synonyms)\n",
    "\n",
    "    features.append(feature)\n",
    "  return features\n",
    "\n",
    "\n",
    "def convert_single_example(ex_index, example, label_list, max_seq_length,\n",
    "                           tokenizer, percentage_synonyms):\n",
    "  \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "  if isinstance(example, PaddingInputExample):\n",
    "    return InputFeatures(\n",
    "        input_ids=[0] * max_seq_length,\n",
    "        input_mask=[0] * max_seq_length,\n",
    "        segment_ids=[0] * max_seq_length,\n",
    "        label_id=0,\n",
    "        is_real_example=False)\n",
    "\n",
    "  # Which tokens to replace with synonyms\n",
    "  set_synonyms = np.random.choice([True, False], max_seq_length,\n",
    "                                  p=[percentage_synonyms, 1 - percentage_synonyms])\n",
    "\n",
    "  label_map = {}\n",
    "  for (i, label) in enumerate(label_list):\n",
    "    label_map[label] = i\n",
    "\n",
    "  tokens_a = tokenizer.tokenize(example.text_a)\n",
    "  tokens_b = None\n",
    "  if example.text_b:\n",
    "    tokens_b = tokenizer.tokenize(example.text_b)\n",
    "\n",
    "  if tokens_b:\n",
    "    # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "    # length is less than the specified length.\n",
    "    # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "    _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "  else:\n",
    "    # Account for [CLS] and [SEP] with \"- 2\"\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "      tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "\n",
    "  # The convention in BERT is:\n",
    "  # (a) For sequence pairs:\n",
    "  #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "  #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
    "  # (b) For single sequences:\n",
    "  #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "  #  type_ids: 0     0   0   0  0     0 0\n",
    "  #\n",
    "  # Where \"type_ids\" are used to indicate whether this is the first\n",
    "  # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "  # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "  # embedding vector (and position vector). This is not *strictly* necessary\n",
    "  # since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "  # it easier for the model to learn the concept of sequences.\n",
    "  #\n",
    "  # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "  # used as the \"sentence vector\". Note that this only makes sense because\n",
    "  # the entire model is fine-tuned.\n",
    "  tokens = []\n",
    "  segment_ids = []\n",
    "  tokens.append(\"[CLS]\")\n",
    "  segment_ids.append(0)\n",
    "  index = 1\n",
    "  for token in tokens_a:\n",
    "    if set_synonyms[index]:\n",
    "        tokens.append(replace_with_synonym(token, tokenizer))\n",
    "    else:\n",
    "        tokens.append(token)\n",
    "    segment_ids.append(0)\n",
    "    index += 1\n",
    "  tokens.append(\"[SEP]\")\n",
    "  segment_ids.append(0)\n",
    "  index += 1\n",
    "\n",
    "  if tokens_b:\n",
    "    for token in tokens_b:\n",
    "      if set_synonyms[index]:\n",
    "        tokens.append(replace_with_synonym(token, tokenizer))\n",
    "      else:\n",
    "        tokens.append(token)\n",
    "      segment_ids.append(1)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(1)\n",
    "\n",
    "  input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "  # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "  # tokens are attended to.\n",
    "  input_mask = [1] * len(input_ids)\n",
    "\n",
    "  # Zero-pad up to the sequence length.\n",
    "  while len(input_ids) < max_seq_length:\n",
    "    input_ids.append(0)\n",
    "    input_mask.append(0)\n",
    "    segment_ids.append(0)\n",
    "\n",
    "  assert len(input_ids) == max_seq_length\n",
    "  assert len(input_mask) == max_seq_length\n",
    "  assert len(segment_ids) == max_seq_length\n",
    "\n",
    "  label_id = label_map[example.label]\n",
    "  if ex_index < 5:\n",
    "    tf.logging.info(\"*** Example ***\")\n",
    "    tf.logging.info(\"guid: %s\" % (example.guid))\n",
    "    tf.logging.info(\"tokens: %s\" % \" \".join(\n",
    "        [tokenization.printable_text(x) for x in tokens]))\n",
    "    tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "    tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "    tf.logging.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "    tf.logging.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
    "\n",
    "  feature = InputFeatures(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids,\n",
    "      label_id=label_id,\n",
    "      is_real_example=True)\n",
    "  return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert.run_classifier import PaddingInputExample, _truncate_seq_pair, InputFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll set sequences to be at most this tokens long.\n",
    "MAX_SEQ_LENGTH = 96\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "# train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "# test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "\n",
    "train_features = convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer, set_synonyms=True, percentage_synonyms=0.2)\n",
    "\n",
    "test_features = convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(tf.keras.Model):\n",
    "    def __init__(self, layers, dropout_keep_proba=0.9, activation=tf.nn.relu):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        \n",
    "        self.dense_layers = []\n",
    "        self.dropout_keep_proba = dropout_keep_proba\n",
    "        \n",
    "        for i, layer_size in enumerate(layers):\n",
    "            self.dense_layers.append(tf.keras.layers.Dense(layer_size, name='DenseLayer_' + str(i), use_bias=True, activation=tf.nn.relu))\n",
    "    \n",
    "    def call(self, logits):\n",
    "        \n",
    "        for layer in self.dense_layers:\n",
    "            logits = layer(logits)\n",
    "            logits = tf.nn.dropout(logits, keep_prob=self.dropout_keep_proba)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "   \n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "#   n_ctx = input_ids.shape[-1].value\n",
    " \n",
    "#   transformer_outputs = bert_outputs['sequence_output']\n",
    "\n",
    "#   index_of_first_token = tf.argmax(segment_ids, axis=1)\n",
    "#   index_of_last_token = tf.argmax((1 - input_mask) * (1 - segment_ids), axis=1) - 1\n",
    "\n",
    "#   tf_range = tf.range(tf.shape(transformer_outputs)[0])\n",
    "#   tf_range = tf.cast(tf_range, tf.int64)\n",
    "    \n",
    "#   index_of_first_token = tf.stack([tf_range, index_of_first_token], axis=1)\n",
    "#   index_of_last_token = tf.stack([tf_range, index_of_last_token], axis=1)\n",
    "    \n",
    "#   first_token_output = tf.gather_nd(transformer_outputs, index_of_first_token)\n",
    "#   last_token_output = tf.gather_nd(transformer_outputs, index_of_last_token)\n",
    "\n",
    "\n",
    "\n",
    "#   # final output size\n",
    "#   weight_size_last_sentence = hidden_size * 3\n",
    "#   layers_for_last_sentence = [weight_size_last_sentence]\n",
    "#   assert weight_size_last_sentence == layers_for_last_sentence[0]\n",
    "#   dense_last_sentence = DenseLayer(layers_for_last_sentence)\n",
    "\n",
    "#   segment_ids_expandend_last_sentence = tf.tile(tf.expand_dims(segment_ids, 2), [1, 1, weight_size_last_sentence])\n",
    "#   segment_ids_expandend_last_sentence = tf.cast(segment_ids_expandend_last_sentence, tf.float32)\n",
    "#   result_last_sentence = dense_last_sentence(transformer_outputs) * segment_ids_expandend_last_sentence\n",
    "\n",
    "#   output_layer_last_sentence = tf.reduce_sum(result_last_sentence, 1)\n",
    "    \n",
    "#   output_layer = output_layer_last_sentence\n",
    "\n",
    "#   =========================================================================================================================\n",
    "#   BIDIRECTIONAL \n",
    "#   # take only last sentences\n",
    "#   last_sentences_transformer_outputs = transformer_outputs * tf.tile(tf.expand_dims(tf.cast(segment_ids, tf.float32), 2), [1, 1, hidden_size])\n",
    "#   # create a list of all LSTM cells we want\n",
    "#   num_layers = 1\n",
    "#   cells_fw = [tf.nn.rnn_cell.GRUCell(num_units=hidden_size) for _ in range(num_layers)]\n",
    "#   cells_bw = [tf.nn.rnn_cell.GRUCell(num_units=hidden_size) for _ in range(num_layers)]\n",
    "\n",
    "#   # we stack the cells together and create one big RNN cell\n",
    "#   cell_fw = tf.nn.rnn_cell.MultiRNNCell(cells_fw)\n",
    "#   cell_bw = tf.nn.rnn_cell.MultiRNNCell(cells_bw)\n",
    "    \n",
    "#   inputs = tf.transpose(last_sentences_transformer_outputs, [1, 0, 2])\n",
    "#   inputs = tf.unstack(inputs, num=MAX_SEQ_LENGTH)\n",
    "# #   inputs = tf.reshape(inputs, [MAX_SEQ_LENGTH, None, hidden_size])\n",
    "\n",
    "#   with tf.variable_scope(\"last_sentence\"):\n",
    "#     outputs, output_state_fw, output_state_bw = tf.nn.static_bidirectional_rnn(cell_fw,\n",
    "#                                                                                cell_bw, \n",
    "#                                                                                inputs, \n",
    "#                                                                                dtype=tf.float32)\n",
    "\n",
    "#   outputs = tf.stack(outputs)\n",
    "#   # outputs size after the transpose [None, MAX_SEQ_LENGTH, hidden_size * 2]\n",
    "#   outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "    \n",
    "#   first_token_output = tf.gather_nd(outputs, index_of_first_token)\n",
    "#   last_token_output = tf.gather_nd(outputs, index_of_last_token)\n",
    "  \n",
    "#   output_layer = tf.concat([first_token_output, last_token_output], 1)\n",
    "#   =========================================================================================================================\n",
    "\n",
    "#   CONV2d\n",
    "\n",
    "#   last_sentences_transformer_outputs = transformer_outputs * tf.tile(tf.expand_dims(tf.cast(segment_ids, tf.float32), 2), [1, 1, hidden_size])\n",
    "  transformer_outputs = bert_outputs['sequence_output']\n",
    "  outputs = tf.expand_dims(transformer_outputs, 3)\n",
    "  # explicitly define the shape of the tensor\n",
    "  outputs = tf.reshape(outputs, [-1, MAX_SEQ_LENGTH, hidden_size, 1])\n",
    "  \n",
    "  conv1 = tf.layers.conv2d(\n",
    "        inputs=outputs,\n",
    "        filters=32,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "#   conv2 = tf.layers.conv2d(\n",
    "#         inputs=pool1,\n",
    "#         filters=32,\n",
    "#         kernel_size=[5, 5],\n",
    "#         padding=\"same\",\n",
    "#         activation=tf.nn.relu)\n",
    "\n",
    "#   pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  conv3 = tf.layers.conv2d(\n",
    "        inputs=pool1,\n",
    "        filters=16,\n",
    "        kernel_size=[5, 5],\n",
    "        padding=\"same\",\n",
    "        activation=tf.nn.relu)\n",
    "\n",
    "  pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  new_hidden_size = pool3.get_shape()[1] * pool3.get_shape()[2] * pool3.get_shape()[3]\n",
    "  output_layer = tf.reshape(pool3, [-1, new_hidden_size])\n",
    "    \n",
    "  print(output_layer)\n",
    "  \n",
    "#   =========================================================================================================================  \n",
    "#   # Highway network\n",
    " \n",
    "#   # project to lower space\n",
    "#   output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "#   output_layer = tf.layers.dense(output_layer, 1024, use_bias=True, activation=tf.nn.relu)\n",
    "\n",
    "  \n",
    "#   num_highway_layers = 5\n",
    "#   for i in range(num_highway_layers):\n",
    "#     # first layer\n",
    "#     W_get = DenseLayer([new_hidden_size], activation=tf.nn.sigmoid)\n",
    "#     W_proj = DenseLayer([new_hidden_size], activation=tf.nn.relu)\n",
    "\n",
    "#     x_gate = W_get(output_layer)\n",
    "#     x_proj = W_proj(output_layer)\n",
    "  \n",
    "#     output_layers = x_gate * x_proj + (1 - x_gate)\n",
    "    \n",
    "\n",
    "#   =========================================================================================================================\n",
    "#   BIDIRECTIONAL all sentences\n",
    "  # take only first sentences\n",
    "#   first_sentences_transformer_outputs = transformer_outputs * tf.tile(tf.expand_dims(tf.cast(input_mask * (1 - segment_ids), tf.float32), 2), [1, 1, hidden_size])\n",
    "#   # create a list of all LSTM cells we want\n",
    "  \n",
    "#   num_layers_f = 1\n",
    "#   cells_fw_f = [tf.nn.rnn_cell.GRUCell(num_units=hidden_size) for _ in range(num_layers_f)]\n",
    "#   cells_bw_f = [tf.nn.rnn_cell.GRUCell(num_units=hidden_size) for _ in range(num_layers_f)]\n",
    "\n",
    "#   # we stack the cells together and create one big RNN cell\n",
    "#   cell_fw_f = tf.nn.rnn_cell.MultiRNNCell(cells_fw_f)\n",
    "#   cell_bw_f = tf.nn.rnn_cell.MultiRNNCell(cells_bw_f)\n",
    "    \n",
    "#   inputs_f = tf.transpose(first_sentences_transformer_outputs, [1, 0, 2])\n",
    "#   inputs_f = tf.unstack(inputs_f, num=MAX_SEQ_LENGTH)\n",
    "# #   inputs = tf.reshape(inputs, [MAX_SEQ_LENGTH, None, hidden_size])\n",
    "\n",
    "#   with tf.variable_scope(\"first_sentences\"):\n",
    "#     outputs_f, output_state_fw_f, output_state_bw_f = tf.nn.static_bidirectional_rnn(cell_fw_f,\n",
    "#                                                                                      cell_bw_f, \n",
    "#                                                                                      inputs_f, \n",
    "#                                                                                      dtype=tf.float32)\n",
    "\n",
    "#   outputs_f = tf.stack(outputs_f)\n",
    "#   # outputs size [None, MAX_SEQ_LENGTH, hidden_size * 2]\n",
    "#   outputs_f = tf.transpose(outputs, [1, 0, 2])\n",
    "    \n",
    "#   index_of_first_token_f = tf.zeros([tf.shape(transformer_outputs)[0]], dtype=tf.int64)\n",
    "#   index_of_last_token_f = tf.argmax(segment_ids, axis=1) - 1\n",
    "    \n",
    "#   index_of_first_token_f = tf.stack([tf_range, index_of_first_token_f], axis=1)\n",
    "#   index_of_last_token_f = tf.stack([tf_range, index_of_last_token_f], axis=1)\n",
    "    \n",
    "#   first_token_output_f = tf.gather_nd(outputs_f, index_of_first_token_f)\n",
    "#   last_token_output_f = tf.gather_nd(outputs_f, index_of_last_token_f)\n",
    "  \n",
    "#   output_layer = tf.concat([first_token_output, last_token_output, first_token_output_f, last_token_output], 1)\n",
    "#   =========================================================================================================================\n",
    "    \n",
    "    \n",
    "#   =========================================================================================================================\n",
    "#   WEIGHTS ON FIRST LAYER    \n",
    "#   weight_size_context = hidden_size * 3\n",
    "#   layers_for_context = [weight_size_context]\n",
    "#   assert weight_size_context == layers_for_context[0]\n",
    "#   dense_context = DenseLayer(layers_for_context)\n",
    "    \n",
    "#   segment_ids_expandend_context = tf.tile(tf.expand_dims((input_mask * (1 - segment_ids)), 2), [1, 1, weight_size_context])\n",
    "#   segment_ids_expandend_context = tf.cast(segment_ids_expandend_context, tf.float32)\n",
    "#   result_context = dense_context(transformer_outputs) * segment_ids_expandend_context\n",
    "\n",
    "#   output_layer_context = tf.reduce_sum(result_context, 1)\n",
    "  \n",
    "# #   output_layer = tf.concat([output_layer_last_sentence, output_layer_context], 1)\n",
    "        \n",
    "#   output_layer = tf.concat([output_layer_last_sentence, first_token_output, last_token_output, output_layer], 1)\n",
    "\n",
    "#   output_layer = bert_outputs[\"pooled_output\"]\n",
    "#   =========================================================================================================================\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):    \n",
    "    # Dropout helps prevent overfitting\n",
    "    logits = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "    logits = tf.layers.dense(logits, 4096, use_bias=True, activation=tf.nn.relu)\n",
    "    logits = tf.nn.dropout(logits, keep_prob=0.9)\n",
    "    logits = tf.layers.dense(logits, num_labels, use_bias=True)\n",
    "    \n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "        }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels\n",
    "          \n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_steps 1403\n"
     ]
    }
   ],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 16\n",
    "# -----------------------------------------------> It was 2e-5\n",
    "LEARNING_RATE = 5e-6\n",
    "NUM_TRAIN_EPOCHS = 6.0\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 500\n",
    "SAVE_SUMMARY_STEPS = 50\n",
    "\n",
    "OUTPUT_DIR = '/cluster/project/infk/courses/machine_perception_19/Sasglentamekaiedo/output_dir'\n",
    "SAVE_RESULTS_DIR = 'results_predictions'\n",
    "\n",
    "N_ESTIMATORS = 40\n",
    "\n",
    "num_train_steps = int(len(train_features) / REPLICATION_FACTOR / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "assert REPLICATION_FACTOR == int(NUM_TRAIN_EPOCHS)\n",
    "    \n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "\n",
    "print('num_train_steps', num_train_steps)\n",
    "\n",
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})\n",
    "\n",
    "test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_predictions(in_contexts, in_last_sentences):\n",
    "    input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = y, label = 0) for x, y in zip(in_contexts, in_last_sentences)] # here, \"\" is just a dummy label\n",
    "    input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "    predictions = estimator.predict(predict_input_fn)\n",
    "    predictions = [prediction['probabilities'] for prediction in predictions]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def combine_predictions(predictions):\n",
    "    my_predictions = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(test):\n",
    "        p_first = np.exp(predictions[i])\n",
    "        p_second = np.exp(predictions[i + 1])\n",
    "\n",
    "        p1 = p_first[0] + p_second[1]\n",
    "        p2 = p_first[1] + p_second[0]\n",
    "\n",
    "        if p1 > p2:\n",
    "            my_predictions.append(1)\n",
    "        else:\n",
    "            my_predictions.append(2)\n",
    "        i += 2\n",
    "        \n",
    "    return np.array(my_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= BEGINNING TRAINING FOR CLASSIFIER 0 learning rate: 5e-06 =========\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 98304), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/sanagnos/.local/lib64/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  0:23:09.302903\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 98304), dtype=float32)\n",
      "Score on val is  0.9096739711384286\n",
      "========= BEGINNING TRAINING FOR CLASSIFIER 1 learning rate: 5e-06 =========\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 98304), dtype=float32)\n",
      "Training took time  0:22:55.360776\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 98304), dtype=float32)\n",
      "Score on val is  0.9037947621592731\n",
      "========= BEGINNING TRAINING FOR CLASSIFIER 2 learning rate: 5e-06 =========\n",
      "Tensor(\"Reshape_1:0\", shape=(?, 98304), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system('rm -rf results_predictions || true')\n",
    "os.system('mkdir results_predictions')\n",
    "\n",
    "true_labels_train = train_unshuffled['class'].values[::2] + 1\n",
    "true_labels_val = test['class'].values[::2] + 1\n",
    "\n",
    "for i in range(N_ESTIMATORS):\n",
    "    os.system('rm -rf ' + str(OUTPUT_DIR) + ' || true')\n",
    "\n",
    "    run_config = tf.estimator.RunConfig(\n",
    "        model_dir=OUTPUT_DIR,\n",
    "        save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "    model_fn = model_fn_builder(\n",
    "      num_labels=len(label_list),\n",
    "      learning_rate=LEARNING_RATE,\n",
    "      num_train_steps=num_train_steps,\n",
    "      num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "      model_fn=model_fn,\n",
    "      config=run_config,\n",
    "      params={\"batch_size\": BATCH_SIZE})\n",
    "    \n",
    "    train_features = shuffle(train_features)\n",
    "    \n",
    "    # Create an input function for training. drop_remainder = True for using TPUs.\n",
    "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "        features=train_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=True,\n",
    "        drop_remainder=False)\n",
    "\n",
    "    print('========= BEGINNING TRAINING FOR CLASSIFIER ' + str(i) + ' learning rate: ' + str(LEARNING_RATE) + ' =========')\n",
    "    current_time = datetime.now()\n",
    "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "    print(\"Training took time \", datetime.now() - current_time)\n",
    "\n",
    "    predictions = get_final_predictions(test['story'].values, test['ending'].values)\n",
    "    val_score = accuracy_score(true_labels_val, combine_predictions(predictions))\n",
    "    print('Score on val is ', val_score)\n",
    "    np.savetxt(os.path.join(\"./\" + SAVE_RESULTS_DIR, \"predictions_test_\" + str(val_score) + '_classifier_' + str(i) + '.csv'), predictions, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3 epochs \n",
    "[5,5] 32 [5,5] 16 max_pool 3 all\n",
    "0.8904329235702833\n",
    "0.5056119722073757\n",
    "0.5082843399251737\n",
    "0.4949225013361839\n",
    "\n",
    "[5,5] 16 [5,5] 16 max_pool 2 all\n",
    "0.897381079636558 \n",
    "0.5050774986638161\n",
    "0.9016568679850347\n",
    "0.900053447354356\n",
    "0.5093532870122929\n",
    "\n",
    "[5,5] 32 [5,5] 32 [5,5] 16 max_pool 2 all 512 at the end / lr = 1e-5 5 epochs\n",
    "0.9027258150721539\n",
    "\n",
    "\n",
    "==================================================\n",
    "ALL 12 EPOCHS unlesss specified otherwise\n",
    "\n",
    "## just take pooled output from BERT:\n",
    "0.8562266167824693\n",
    "0.8722608230892571\n",
    "0.8583645109567076\n",
    "0.8599679315873864\n",
    "\n",
    "\n",
    "## only last sentece layers = [hidden_size]:\n",
    "0.8679850347407804\n",
    "0.8711918760021379\n",
    "0.877605558524853\n",
    "0.8765366114377339\n",
    "0.8674505611972207\n",
    "\n",
    "## same but for 3 epochs\n",
    "0.8760021378941742\n",
    "0.8722608230892571\n",
    "0.8743987172634955\n",
    "0.8797434526990914\n",
    "0.8797434526990914\n",
    "\n",
    "## only last sentece layers = [hidden_size * 5] 3 epochs:\n",
    "0.8813468733297701\n",
    "0.8818813468733298\n",
    "0.8733297701763763\n",
    "0.8808123997862106\n",
    "0.8733297701763763\n",
    "0.8738642437199359\n",
    "\n",
    "## only last sentece 3 epochs:[hidden_size * 5, hidden_size * 3, weight_size_last_sentence]\n",
    "0.8786745056119722\n",
    "0.8717263495456975\n",
    "\n",
    "## only last sentece layers = [hidden_size] 3 epochs with random_replacement 0.1:\n",
    "0.8850881881346874\n",
    "0.8743987172634955\n",
    "0.8685195082843399\n",
    "0.882950293960449\n",
    "0.8653126670229824\n",
    "\n",
    "## only last sentece layers = [hidden_size * 3] 3 epochs with random_replacement 0.2:\n",
    "0.8818813468733298\n",
    "0.8760021378941742\n",
    "0.882950293960449\n",
    "0.8808123997862106\n",
    "0.8743987172634955\n",
    "\n",
    "## only last sentece layers = [hidden_size * 3] 5 epochs with random_replacement 0.1:\n",
    "0.8695884553714591\n",
    "0.8647781934794228\n",
    "\n",
    "## only last sentece layers = [hidden_size * 3] 5 epochs with random_replacement 0.2:\n",
    "0.8840192410475681\n",
    "0.8813468733297701\n",
    "0.8797434526990914\n",
    "\n",
    "## concat of last sentence and context [hidden_size], [hidden_size] 3 epochs:\n",
    "0.8711918760021379\n",
    "0.8711918760021379\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "mask = tf.constant([[0,0,1,1,1,0],\n",
    "                    [0,0,0,1,1,0]])\n",
    "\n",
    "mask1 = tf.constant([[1,1,1,1,1,0],\n",
    "                     [1,1,1,1,1,0]])\n",
    "\n",
    "\n",
    "features = tf.ones([2,6,3], dtype=tf.float32)\n",
    "\n",
    "# weights = tf.get_variable('weights', [3,3])\n",
    "weights = tf.constant([1,2,3], dtype=tf.float32)\n",
    "\n",
    "mask_expanded = tf.tile(tf.expand_dims(mask, 2), [1,1,3])\n",
    "mask_expanded = tf.cast(mask_expanded, tf.float32)\n",
    "r = (features * weights) * mask_expanded\n",
    "\n",
    "r = tf.reduce_sum(r, 1)\n",
    "\n",
    "mask_expanded1 = tf.tile(tf.expand_dims((mask1 * (1 - mask)), 2), [1,1,3])\n",
    "mask_expanded1 = tf.cast(mask_expanded1, tf.float32)\n",
    "r1 = (features * weights) * mask_expanded1\n",
    "\n",
    "r1 = tf.reduce_sum(r1, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(r))\n",
    "    print(sess.run(r1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "SAVE_RESULTS_DIR = 'results_predictions'\n",
    "\n",
    "\n",
    "files = [f for f in listdir(SAVE_RESULTS_DIR) if isfile(join(SAVE_RESULTS_DIR, f))]\n",
    "\n",
    "true_labels_train = train_unshuffled['class'].values[::2] + 1\n",
    "true_labels_test = test['class'].values[::2] + 1\n",
    "\n",
    "classifiers = [int(file.split(\"_\")[4].split(\".\")[0]) for file in files]\n",
    "num_classifiers = np.max(classifiers)\n",
    "\n",
    "predictions_train = []\n",
    "predictions_test = []\n",
    "for i in range(num_classifiers + 1):\n",
    "    test_file = [x for x in files if 'classifier_' + str(i) in x][0]\n",
    "    \n",
    "    accuracy = float(test_file.split('_')[2])\n",
    "    \n",
    "#     if accuracy < 0.9:\n",
    "#         continue\n",
    "    \n",
    "    predictions_file_test = np.genfromtxt(os.path.join(\"./\" + SAVE_RESULTS_DIR, test_file), delimiter=',')\n",
    "    predictions_test.append(predictions_file_test)\n",
    "#     print(f'For classifier {i:2d} train accuracy {accuracy_score(true_labels_train, combine_predictions(predictions_file_train)):.4f} and test accuracy {accuracy_score(true_labels_test, combine_predictions(predictions_file_test)):.4f}')\n",
    "    print(f'For classifier {i:2d} test accuracy {accuracy:.4f}')\n",
    "    \n",
    "def print_ensemble_predictions(predictions, true_labels):\n",
    "    preds_mode = [combine_predictions(p) for p in predictions]\n",
    "    preds_mode = np.array(preds_mode)\n",
    "    preds_mode = stats.mode(preds_mode)[0][0]\n",
    "\n",
    "    print('ENSEMBLE ACCURACY MODE')\n",
    "    print(accuracy_score(true_labels, preds_mode))\n",
    "\n",
    "    preds_prob = np.mean(predictions, axis=0)\n",
    "    preds_prob = combine_predictions(preds_prob)\n",
    "\n",
    "    print('ENSEMBLE ACCURACY PROB MEAN ON LOGS')\n",
    "    print(accuracy_score(true_labels, preds_prob))\n",
    "\n",
    "\n",
    "    preds_prob = np.log(np.mean(np.exp(predictions), axis=0))\n",
    "    preds_prob = combine_predictions(preds_prob)\n",
    "\n",
    "    print('ENSEMBLE ACCURACY PROB MEAN ON PROBS')\n",
    "    print(accuracy_score(true_labels, preds_prob))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "# print_ensemble_predictions(predictions_train, true_labels_train)\n",
    "print_ensemble_predictions(predictions_test, true_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### OLD\n",
    "\n",
    "\n",
    "small_bert (whole val and whole test)\n",
    "\n",
    "output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "logits = tf.layers.dense(output_layer, 128, use_bias=True, activation=tf.nn.sigmoid)\n",
    "logits = tf.nn.dropout(logits, keep_prob=0.9)\n",
    "logits = tf.layers.dense(logits, num_labels, use_bias=True)\n",
    "\n",
    "For classifier  0 train accuracy 1.0000 and test accuracy 0.8391\n",
    "For classifier  1 train accuracy 1.0000 and test accuracy 0.8343\n",
    "For classifier  2 train accuracy 1.0000 and test accuracy 0.8386\n",
    "For classifier  3 train accuracy 1.0000 and test accuracy 0.8311\n",
    "For classifier  4 train accuracy 1.0000 and test accuracy 0.8434\n",
    "For classifier  5 train accuracy 1.0000 and test accuracy 0.8397\n",
    "For classifier  6 train accuracy 1.0000 and test accuracy 0.8434\n",
    "For classifier  7 train accuracy 1.0000 and test accuracy 0.8418\n",
    "For classifier  8 train accuracy 1.0000 and test accuracy 0.8359\n",
    "For classifier  9 train accuracy 1.0000 and test accuracy 0.8487\n",
    "For classifier 10 train accuracy 1.0000 and test accuracy 0.8332\n",
    "For classifier 11 train accuracy 1.0000 and test accuracy 0.8429\n",
    "For classifier 12 train accuracy 1.0000 and test accuracy 0.8397\n",
    "For classifier 13 train accuracy 1.0000 and test accuracy 0.8407\n",
    "For classifier 14 train accuracy 1.0000 and test accuracy 0.8365\n",
    "ENSEMBLE ACCURACY MODE\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "1.0\n",
    "\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.8722608230892571\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.8786745056119722\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.8786745056119722\n",
    "\n",
    "big_bert (whole val and whole test)\n",
    "For classifier  0 train accuracy 1.0000 and test accuracy 0.8691\n",
    "For classifier  1 train accuracy 1.0000 and test accuracy 0.8664\n",
    "For classifier  2 train accuracy 1.0000 and test accuracy 0.8680\n",
    "For classifier  3 train accuracy 1.0000 and test accuracy 0.8562\n",
    "For classifier  4 train accuracy 0.9984 and test accuracy 0.8397\n",
    "For classifier  5 train accuracy 1.0000 and test accuracy 0.8696\n",
    "For classifier  6 train accuracy 1.0000 and test accuracy 0.8381\n",
    "For classifier  7 train accuracy 1.0000 and test accuracy 0.8589\n",
    "For classifier  8 train accuracy 1.0000 and test accuracy 0.8632\n",
    "For classifier  9 train accuracy 1.0000 and test accuracy 0.8600\n",
    "For classifier 10 train accuracy 1.0000 and test accuracy 0.8701\n",
    "For classifier 11 train accuracy 1.0000 and test accuracy 0.8696\n",
    "For classifier 12 train accuracy 0.9947 and test accuracy 0.8268\n",
    "For classifier 13 train accuracy 1.0000 and test accuracy 0.8653\n",
    "For classifier 14 train accuracy 0.9995 and test accuracy 0.8044\n",
    "ENSEMBLE ACCURACY MODE\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "1.0\n",
    "\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.8979155531801176\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9021913415285944\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.8984500267236771\n",
    "\n",
    "big bert [512]\n",
    "\n",
    "For classifier  0 train accuracy 1.0000 and test accuracy 0.8792\n",
    "For classifier  1 train accuracy 1.0000 and test accuracy 0.8787\n",
    "For classifier  2 train accuracy 0.9989 and test accuracy 0.8952\n",
    "For classifier  3 train accuracy 1.0000 and test accuracy 0.8803\n",
    "For classifier  4 train accuracy 1.0000 and test accuracy 0.8632\n",
    "For classifier  5 train accuracy 1.0000 and test accuracy 0.8717\n",
    "For classifier  6 train accuracy 1.0000 and test accuracy 0.8797\n",
    "For classifier  7 train accuracy 1.0000 and test accuracy 0.8733\n",
    "For classifier  8 train accuracy 1.0000 and test accuracy 0.8781\n",
    "For classifier  9 train accuracy 1.0000 and test accuracy 0.8712\n",
    "For classifier 10 train accuracy 1.0000 and test accuracy 0.8616\n",
    "For classifier 11 train accuracy 1.0000 and test accuracy 0.8669\n",
    "For classifier 12 train accuracy 0.9995 and test accuracy 0.8589\n",
    "For classifier 13 train accuracy 1.0000 and test accuracy 0.8632\n",
    "For classifier 14 train accuracy 1.0000 and test accuracy 0.8803\n",
    "ENSEMBLE ACCURACY MODE\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "1.0\n",
    "\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.9048637092463923\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9075360769641903\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.9048637092463923\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "one weight [hidden_size, hidden_size] all between first_sep_token and first_pad_token (15 epochs)\n",
    "\n",
    "For classifier  0 train accuracy 1.0000 and test accuracy 0.8787\n",
    "For classifier  1 train accuracy 1.0000 and test accuracy 0.8899\n",
    "For classifier  2 train accuracy 1.0000 and test accuracy 0.8867\n",
    "For classifier  3 train accuracy 1.0000 and test accuracy 0.8771\n",
    "For classifier  4 train accuracy 0.9995 and test accuracy 0.8904\n",
    "For classifier  5 train accuracy 1.0000 and test accuracy 0.8883\n",
    "For classifier  6 train accuracy 1.0000 and test accuracy 0.8856\n",
    "For classifier  7 train accuracy 1.0000 and test accuracy 0.8840\n",
    "For classifier  8 train accuracy 1.0000 and test accuracy 0.8830\n",
    "For classifier  9 train accuracy 1.0000 and test accuracy 0.8942\n",
    "For classifier 10 train accuracy 1.0000 and test accuracy 0.8985\n",
    "For classifier 11 train accuracy 1.0000 and test accuracy 0.8910\n",
    "For classifier 12 train accuracy 1.0000 and test accuracy 0.8936\n",
    "For classifier 13 train accuracy 1.0000 and test accuracy 0.8936\n",
    "For classifier 14 train accuracy 1.0000 and test accuracy 0.8862\n",
    "ENSEMBLE ACCURACY MODE\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "1.0\n",
    "\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.9102084446819882\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9064671298770711\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.9075360769641903\n",
    "\n",
    "---------------------------------------------------------------------------------\n",
    "replace words 0.2 only last sentece layers = [hidden_size * 3] 5 epochs\n",
    "\n",
    "For classifier  0 test accuracy 0.8872\n",
    "For classifier  1 test accuracy 0.8915\n",
    "For classifier  2 test accuracy 0.9017\n",
    "For classifier  3 test accuracy 0.8968\n",
    "For classifier  4 test accuracy 0.8958\n",
    "For classifier  6 test accuracy 0.8936\n",
    "For classifier  7 test accuracy 0.8936\n",
    "For classifier  8 test accuracy 0.9027\n",
    "For classifier  9 test accuracy 0.8920\n",
    "For classifier 10 test accuracy 0.8947\n",
    "For classifier 11 test accuracy 0.8958\n",
    "For classifier 12 test accuracy 0.8968\n",
    "For classifier 13 test accuracy 0.9033\n",
    "For classifier 14 test accuracy 0.8824\n",
    "For classifier 15 test accuracy 0.8990\n",
    "For classifier 16 test accuracy 0.9022\n",
    "For classifier 17 test accuracy 0.8931\n",
    "For classifier 18 test accuracy 0.8958\n",
    "For classifier 19 test accuracy 0.8867\n",
    "For classifier 20 test accuracy 0.9006\n",
    "For classifier 21 test accuracy 0.8936\n",
    "For classifier 22 test accuracy 0.8985\n",
    "For classifier 23 test accuracy 0.8931\n",
    "For classifier 24 test accuracy 0.9001\n",
    "For classifier 25 test accuracy 0.8920\n",
    "For classifier 26 test accuracy 0.9017\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.914484233030465\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9139497594869054\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.9134152859433458\n",
    "\n",
    "---------------------------------------------------------------------------------\n",
    "replace words 0.2 bidirectional lstm only last sentence num_layers=1 hidden_size=hidden_size\n",
    "\n",
    "For classifier  0 test accuracy 0.8899\n",
    "For classifier  1 test accuracy 0.8936\n",
    "For classifier  2 test accuracy 0.8920\n",
    "For classifier  3 test accuracy 0.8985\n",
    "For classifier  4 test accuracy 0.8846\n",
    "For classifier  5 test accuracy 0.8931\n",
    "For classifier  6 test accuracy 0.9027\n",
    "For classifier  7 test accuracy 0.8958\n",
    "For classifier  8 test accuracy 0.9017\n",
    "For classifier  9 test accuracy 0.9118\n",
    "For classifier 10 test accuracy 0.9033\n",
    "For classifier 11 test accuracy 0.9038\n",
    "For classifier 12 test accuracy 0.8963\n",
    "For classifier 13 test accuracy 0.8942\n",
    "For classifier 14 test accuracy 0.8867\n",
    "For classifier 15 test accuracy 0.8952\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.9155531801175841\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.911811865312667\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.911811865312667\n",
    "\n",
    "For classifier  0 test accuracy 0.9038\n",
    "For classifier  1 test accuracy 0.9081\n",
    "For classifier  2 test accuracy 0.9027\n",
    "For classifier  3 test accuracy 0.8936\n",
    "For classifier  4 test accuracy 0.9070\n",
    "For classifier  5 test accuracy 0.9038\n",
    "For classifier  6 test accuracy 0.8990\n",
    "For classifier  7 test accuracy 0.9043\n",
    "For classifier  8 test accuracy 0.9001\n",
    "For classifier  9 test accuracy 0.8968\n",
    "For classifier 10 test accuracy 0.9001\n",
    "For classifier 11 test accuracy 0.9033\n",
    "For classifier 12 test accuracy 0.9017\n",
    "For classifier 13 test accuracy 0.8968\n",
    "For classifier 14 test accuracy 0.8888\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.914484233030465\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9166221272047034\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.914484233030465\n",
    "\n",
    "---------------------------------------------------------------------------------\n",
    "replace words 0.2 bidirectional gru only last sentence num_layers=1 hidden_size=hidden_size\n",
    "\n",
    "For classifier  0 test accuracy 0.8947\n",
    "For classifier  1 test accuracy 0.9065\n",
    "For classifier  2 test accuracy 0.9118\n",
    "For classifier  3 test accuracy 0.8958\n",
    "For classifier  4 test accuracy 0.8936\n",
    "For classifier  5 test accuracy 0.8920\n",
    "For classifier  6 test accuracy 0.9006\n",
    "For classifier  7 test accuracy 0.8958\n",
    "For classifier  8 test accuracy 0.9022\n",
    "For classifier  9 test accuracy 0.8926\n",
    "For classifier 10 test accuracy 0.9033\n",
    "For classifier 11 test accuracy 0.8840\n",
    "For classifier 12 test accuracy 0.8904\n",
    "For classifier 14 test accuracy 0.8974\n",
    "For classifier 15 test accuracy 0.8947\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.911811865312667\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9128808123997862\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.914484233030465\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "conv2d [5,5] [5,5]\n",
    "\n",
    "For classifier  0 test accuracy 0.9033\n",
    "For classifier  1 test accuracy 0.9017\n",
    "For classifier  2 test accuracy 0.8947\n",
    "For classifier  3 test accuracy 0.8979\n",
    "For classifier  4 test accuracy 0.9043\n",
    "For classifier  5 test accuracy 0.9081\n",
    "For classifier  6 test accuracy 0.9086\n",
    "For classifier  7 test accuracy 0.9065\n",
    "For classifier  8 test accuracy 0.8872\n",
    "For classifier  9 test accuracy 0.8947\n",
    "For classifier 10 test accuracy 0.8936\n",
    "For classifier 11 test accuracy 0.8990\n",
    "For classifier 12 test accuracy 0.9027\n",
    "For classifier 13 test accuracy 0.5168\n",
    "For classifier 14 test accuracy 0.9054\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.9203634420096205\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9182255478353821\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.9203634420096205\n",
    "\n",
    "---------------------------------------------------------------------------\n",
    "[5,5] 32 [5,5] 32 [5,5] 16 512 at the end 5 epochs lr 1e-5\n",
    "\n",
    "For classifier  0 test accuracy 0.8920\n",
    "For classifier  1 test accuracy 0.5029\n",
    "For classifier  2 test accuracy 0.9086\n",
    "For classifier  3 test accuracy 0.9081\n",
    "For classifier  4 test accuracy 0.8840\n",
    "For classifier  5 test accuracy 0.6104\n",
    "For classifier  6 test accuracy 0.9081\n",
    "For classifier  7 test accuracy 0.9070\n",
    "For classifier  8 test accuracy 0.9065\n",
    "For classifier  9 test accuracy 0.9102\n",
    "For classifier 10 test accuracy 0.9070\n",
    "For classifier 11 test accuracy 0.9033\n",
    "For classifier 12 test accuracy 0.9001\n",
    "For classifier 13 test accuracy 0.9043\n",
    "For classifier 14 test accuracy 0.5029\n",
    "For classifier 15 test accuracy 0.9043\n",
    "For classifier 16 test accuracy 0.5115\n",
    "For classifier 17 test accuracy 0.5077\n",
    "For classifier 18 test accuracy 0.8862\n",
    "For classifier 19 test accuracy 0.9070\n",
    "For classifier 20 test accuracy 0.8963\n",
    "For classifier 21 test accuracy 0.9049\n",
    "For classifier 22 test accuracy 0.9022\n",
    "For classifier 23 test accuracy 0.8862\n",
    "For classifier 24 test accuracy 0.8995\n",
    "For classifier 25 test accuracy 0.8990\n",
    "For classifier 26 test accuracy 0.8899\n",
    "For classifier 27 test accuracy 0.8648\n",
    "For classifier 28 test accuracy 0.9086\n",
    "For classifier 29 test accuracy 0.8776\n",
    "For classifier 30 test accuracy 0.9049\n",
    "For classifier 31 test accuracy 0.9054\n",
    "For classifier 32 test accuracy 0.9075\n",
    "For classifier 33 test accuracy 0.9027\n",
    "For classifier 34 test accuracy 0.4992\n",
    "For classifier 35 test accuracy 0.8936\n",
    "For classifier 36 test accuracy 0.9054\n",
    "For classifier 37 test accuracy 0.8952\n",
    "For classifier 38 test accuracy 0.8952\n",
    "For classifier 39 test accuracy 0.9011\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.9155531801175841\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9134152859433458\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.914484233030465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
