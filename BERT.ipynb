{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Augmentation: we perform synonym and random\n",
    "word replacement with NLTK and WordNet on the contexts\n",
    "of the SQuAD dataset. Questions are left unchanged. We\n",
    "explored different strategies of synonym replacement\n",
    "(sampling rate, +random words, +stop words) and\n",
    "injected different amount of augmented data (x0.33, x1, x2,\n",
    "x3) on top of the original data in our experiments.\n",
    "● For each word in a context paragraph\n",
    "○ 20% of the time:\n",
    "call replace_synonym\n",
    "■ if exists synonyms:\n",
    "replace with a random synonym\n",
    "■ otherwise:\n",
    "replace with a random word\n",
    "○ 80% of the time: remain unchanged\n",
    "\n",
    "http://web.stanford.edu/class/cs224n/posters/15845024.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)  # suppress some deprecation warnings\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "data_directory = './data'\n",
    "\n",
    "data_val = pd.read_csv(os.path.join(data_directory, 'cloze_test_val__spring2016 - cloze_test_ALL_val.csv'), header='infer')\n",
    "data_test = pd.read_csv(os.path.join(data_directory, 'cloze_test_test__spring2016 - cloze_test_ALL_test.csv'), header='infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0527 14:53:19.058641 47043955117504 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cluster/home/sanagnos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /cluster/home/sanagnos/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /cluster/home/sanagnos/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data_val):\n",
    "    contexts = list()\n",
    "    last_sentences = list()\n",
    "    classes = list()\n",
    "    for pos in range(len(data_val)):\n",
    "        story_start = data_val.iloc[pos][['InputSentence' + str(i) for i in [1, 2, 3, 4]]].values\n",
    "        \n",
    "        contexts.append(\" \".join(story_start))\n",
    "        last_sentences.append(data_val.iloc[pos]['RandomFifthSentenceQuiz1'])\n",
    "        contexts.append(\" \".join(story_start))\n",
    "        last_sentences.append(data_val.iloc[pos]['RandomFifthSentenceQuiz2'])\n",
    "        \n",
    "        if data_val.iloc[pos]['AnswerRightEnding'] == 1:\n",
    "            classes.append(0)\n",
    "            classes.append(1)\n",
    "        else:\n",
    "            classes.append(1)\n",
    "            classes.append(0)\n",
    "            \n",
    "    return pd.DataFrame({'story': contexts, 'ending': last_sentences, 'class': classes})\n",
    "\n",
    "val_pd = create_dataset(data_val)\n",
    "test_pd = create_dataset(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3742\n",
      "3742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "train = shuffle(val_pd)\n",
    "train_unshuffled = val_pd\n",
    "test = test_pd\n",
    "\n",
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_COLUMN = 'story'\n",
    "ENDING_COLUMN = 'ending'\n",
    "LABEL_COLUMN = 'class'\n",
    "\n",
    "# label_list is 0 for a true story and 1 for a false story\n",
    "label_list = [0, 1]\n",
    "\n",
    "REPLICATION_FACTOR = 5\n",
    "\n",
    "train_InputExamples = pd.concat([train]*REPLICATION_FACTOR).apply(lambda x: \n",
    "                                                                  bert.run_classifier.InputExample(guid=None,\n",
    "                                                                  text_a = x[CONTEXT_COLUMN], \n",
    "                                                                  text_b = x[ENDING_COLUMN], \n",
    "                                                                  label = x[LABEL_COLUMN]), axis = 1)\n",
    "\n",
    "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[CONTEXT_COLUMN], \n",
    "                                                                   text_b = x[ENDING_COLUMN], \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a path to an uncased (all lowercase) version of BERT\n",
    "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "# BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-24_H-1024_A-16/1\"\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "        with tf.Session() as sess:\n",
    "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert.run_classifier import PaddingInputExample, _truncate_seq_pair, InputFeatures\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "\n",
    "def replace_with_synonym(token, tokenizer):\n",
    "  new_token = token\n",
    "  synonyms = []\n",
    "  for syn in wordnet.synsets(token):\n",
    "    for l in syn.lemmas():\n",
    "      synonyms.append(l.name())\n",
    "  if len(synonyms) > 0:\n",
    "    new_token = tokenizer.tokenize(random.choice(synonyms))[0]\n",
    "#     print(token, new_token)\n",
    "  return new_token\n",
    "\n",
    "\n",
    "def convert_examples_to_features(examples, label_list, max_seq_length,\n",
    "                                 tokenizer, set_synonyms=False, percentage_synonyms=0.2):\n",
    "  \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "  \n",
    "  if set_synonyms == False:\n",
    "    percentage_synonyms = 0\n",
    "\n",
    "  features = []\n",
    "  for (ex_index, example) in enumerate(examples):\n",
    "    if ex_index % 10000 == 0:\n",
    "      tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "\n",
    "    feature = convert_single_example(ex_index, example, label_list,\n",
    "                                     max_seq_length, tokenizer, percentage_synonyms)\n",
    "\n",
    "    features.append(feature)\n",
    "  return features\n",
    "\n",
    "\n",
    "def convert_single_example(ex_index, example, label_list, max_seq_length,\n",
    "                           tokenizer, percentage_synonyms):\n",
    "  \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "  if isinstance(example, PaddingInputExample):\n",
    "    return InputFeatures(\n",
    "        input_ids=[0] * max_seq_length,\n",
    "        input_mask=[0] * max_seq_length,\n",
    "        segment_ids=[0] * max_seq_length,\n",
    "        label_id=0,\n",
    "        is_real_example=False)\n",
    "\n",
    "  # Which tokens to replace with synonyms\n",
    "  set_synonyms = np.random.choice([True, False], max_seq_length,\n",
    "                                  p=[percentage_synonyms, 1 - percentage_synonyms])\n",
    "\n",
    "  label_map = {}\n",
    "  for (i, label) in enumerate(label_list):\n",
    "    label_map[label] = i\n",
    "\n",
    "  tokens_a = tokenizer.tokenize(example.text_a)\n",
    "  tokens_b = None\n",
    "  if example.text_b:\n",
    "    tokens_b = tokenizer.tokenize(example.text_b)\n",
    "\n",
    "  if tokens_b:\n",
    "    # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
    "    # length is less than the specified length.\n",
    "    # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
    "    _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
    "  else:\n",
    "    # Account for [CLS] and [SEP] with \"- 2\"\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "      tokens_a = tokens_a[0:(max_seq_length - 2)]\n",
    "\n",
    "  # The convention in BERT is:\n",
    "  # (a) For sequence pairs:\n",
    "  #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
    "  #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
    "  # (b) For single sequences:\n",
    "  #  tokens:   [CLS] the dog is hairy . [SEP]\n",
    "  #  type_ids: 0     0   0   0  0     0 0\n",
    "  #\n",
    "  # Where \"type_ids\" are used to indicate whether this is the first\n",
    "  # sequence or the second sequence. The embedding vectors for `type=0` and\n",
    "  # `type=1` were learned during pre-training and are added to the wordpiece\n",
    "  # embedding vector (and position vector). This is not *strictly* necessary\n",
    "  # since the [SEP] token unambiguously separates the sequences, but it makes\n",
    "  # it easier for the model to learn the concept of sequences.\n",
    "  #\n",
    "  # For classification tasks, the first vector (corresponding to [CLS]) is\n",
    "  # used as the \"sentence vector\". Note that this only makes sense because\n",
    "  # the entire model is fine-tuned.\n",
    "  tokens = []\n",
    "  segment_ids = []\n",
    "  tokens.append(\"[CLS]\")\n",
    "  segment_ids.append(0)\n",
    "  index = 1\n",
    "  for token in tokens_a:\n",
    "    if set_synonyms[index]:\n",
    "        tokens.append(replace_with_synonym(token, tokenizer))\n",
    "    else:\n",
    "        tokens.append(token)\n",
    "    segment_ids.append(0)\n",
    "    index += 1\n",
    "  tokens.append(\"[SEP]\")\n",
    "  segment_ids.append(0)\n",
    "  index += 1\n",
    "\n",
    "  if tokens_b:\n",
    "    for token in tokens_b:\n",
    "      if set_synonyms[index]:\n",
    "        tokens.append(replace_with_synonym(token, tokenizer))\n",
    "      else:\n",
    "        tokens.append(token)\n",
    "      segment_ids.append(1)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(1)\n",
    "\n",
    "  input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "  # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "  # tokens are attended to.\n",
    "  input_mask = [1] * len(input_ids)\n",
    "\n",
    "  # Zero-pad up to the sequence length.\n",
    "  while len(input_ids) < max_seq_length:\n",
    "    input_ids.append(0)\n",
    "    input_mask.append(0)\n",
    "    segment_ids.append(0)\n",
    "\n",
    "  assert len(input_ids) == max_seq_length\n",
    "  assert len(input_mask) == max_seq_length\n",
    "  assert len(segment_ids) == max_seq_length\n",
    "\n",
    "  label_id = label_map[example.label]\n",
    "  if ex_index < 5:\n",
    "    tf.logging.info(\"*** Example ***\")\n",
    "    tf.logging.info(\"guid: %s\" % (example.guid))\n",
    "    tf.logging.info(\"tokens: %s\" % \" \".join(\n",
    "        [tokenization.printable_text(x) for x in tokens]))\n",
    "    tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "    tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "    tf.logging.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "    tf.logging.info(\"label: %s (id = %d)\" % (example.label, label_id))\n",
    "\n",
    "  feature = InputFeatures(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids,\n",
    "      label_id=label_id,\n",
    "      is_real_example=True)\n",
    "  return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll set sequences to be at most this tokens long.\n",
    "MAX_SEQ_LENGTH = 96\n",
    "# Convert our train and test features to InputFeatures that BERT understands.\n",
    "train_features = convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer,\n",
    "                                              set_synonyms=True, percentage_synonyms=0.2)\n",
    "\n",
    "test_features = convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023, 2182, 1005, 1055, 2019, 2742, 1997, 2478, 1996, 14324, 19204, 17629, 1064, 1064, 1064, 3231]\n",
      "[2023, 2182, 1005, 1055, 2019, 2742, 1997, 2478, 1996, 14324, 19204, 17629, 1064, 1064, 1064, 3231, 101]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(\"This here's an example of using the BERT tokenizer ||| test\")\n",
    "print(tokenizer.convert_tokens_to_ids(tokens))\n",
    "tokens.append(\"[CLS]\")\n",
    "print(tokenizer.convert_tokens_to_ids(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(tf.keras.Model):\n",
    "    def __init__(self, layers, dropout_keep_proba=0.9, activation=tf.nn.relu):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        \n",
    "        self.dense_layers = []\n",
    "        self.dropout_keep_proba = dropout_keep_proba\n",
    "        \n",
    "        for i, layer_size in enumerate(layers):\n",
    "            self.dense_layers.append(tf.keras.layers.Dense(layer_size, name='DenseLayer_' + str(i), use_bias=True, activation=tf.nn.relu))\n",
    "    \n",
    "    def call(self, logits):\n",
    "        \n",
    "        for layer in self.dense_layers:\n",
    "            logits = layer(logits)\n",
    "            logits = tf.nn.dropout(logits, keep_prob=self.dropout_keep_proba)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
    "                 num_labels):\n",
    "  \"\"\"Creates a classification model.\"\"\"\n",
    "\n",
    "  bert_module = hub.Module(\n",
    "      BERT_MODEL_HUB,\n",
    "      trainable=True)\n",
    "  bert_inputs = dict(\n",
    "      input_ids=input_ids,\n",
    "      input_mask=input_mask,\n",
    "      segment_ids=segment_ids)\n",
    "  bert_outputs = bert_module(\n",
    "      inputs=bert_inputs,\n",
    "      signature=\"tokens\",\n",
    "      as_dict=True)\n",
    "\n",
    "  output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "  hidden_size = output_layer.shape[-1].value\n",
    "  n_ctx = input_ids.shape[-1].value\n",
    " \n",
    "  transformer_outputs = bert_outputs['sequence_output']\n",
    "\n",
    "  # final output size\n",
    "  weight_size_last_sentence = hidden_size * 3\n",
    "  layers_for_last_sentence = [weight_size_last_sentence]\n",
    "  assert weight_size_last_sentence == layers_for_last_sentence[-1]\n",
    "  dense_last_sentence = DenseLayer(layers_for_last_sentence)\n",
    "    \n",
    "  segment_ids_expandend = tf.tile(tf.expand_dims(segment_ids, 2), [1, 1, weight_size_last_sentence])\n",
    "  segment_ids_expandend = tf.cast(segment_ids_expandend, tf.float32)\n",
    "  result = dense_last_sentence(transformer_outputs) * segment_ids_expandend\n",
    "\n",
    "  output_layer_last_sentence = tf.reduce_sum(result, 1)\n",
    "        \n",
    "  output_layer = output_layer_last_sentence\n",
    "\n",
    "  with tf.variable_scope(\"loss\"):\n",
    "\n",
    "    # Dropout helps prevent overfitting\n",
    "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "    logits = tf.layers.dense(output_layer, 512, use_bias=True, activation=tf.nn.sigmoid)\n",
    "    logits = tf.nn.dropout(logits, keep_prob=0.9)\n",
    "    logits = tf.layers.dense(logits, num_labels, use_bias=True)\n",
    "\n",
    "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "    \n",
    "    # Convert labels into one-hot encoding\n",
    "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "    if is_predicting:\n",
    "      return (predicted_labels, log_probs)\n",
    "\n",
    "    # If we're train/eval, compute loss between predicted and actual label\n",
    "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "    loss = tf.reduce_mean(per_example_loss)\n",
    "    return (loss, predicted_labels, log_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
    "                     num_warmup_steps):\n",
    "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
    "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
    "\n",
    "    input_ids = features[\"input_ids\"]\n",
    "    input_mask = features[\"input_mask\"]\n",
    "    segment_ids = features[\"segment_ids\"]\n",
    "    label_ids = features[\"label_ids\"]\n",
    "\n",
    "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "    \n",
    "    # TRAIN and EVAL\n",
    "    if not is_predicting:\n",
    "\n",
    "      (loss, predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      train_op = bert.optimization.create_optimizer(\n",
    "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "      # Calculate evaluation metrics. \n",
    "      def metric_fn(label_ids, predicted_labels):\n",
    "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "        return {\n",
    "            \"eval_accuracy\": accuracy,\n",
    "        }\n",
    "\n",
    "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "          loss=loss,\n",
    "          train_op=train_op)\n",
    "      else:\n",
    "          return tf.estimator.EstimatorSpec(mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=eval_metrics)\n",
    "    else:\n",
    "      (predicted_labels, log_probs) = create_model(\n",
    "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "\n",
    "      predictions = {\n",
    "          'probabilities': log_probs,\n",
    "          'labels': predicted_labels\n",
    "      }\n",
    "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "  return model_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_train_steps 1169\n"
     ]
    }
   ],
   "source": [
    "# Compute train and warmup steps from batch size\n",
    "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
    "BATCH_SIZE = 16\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_TRAIN_EPOCHS = 5.0\n",
    "# Warmup is a period of time where hte learning rate \n",
    "# is small and gradually increases--usually helps training.\n",
    "WARMUP_PROPORTION = 0.1\n",
    "# Model configs\n",
    "SAVE_CHECKPOINTS_STEPS = 50000\n",
    "SAVE_SUMMARY_STEPS = 100000\n",
    "\n",
    "OUTPUT_DIR = 'output_dir'\n",
    "SAVE_RESULTS_DIR = 'results_predictions'\n",
    "\n",
    "N_ESTIMATORS = 15\n",
    "\n",
    "# Compute # train and warmup steps from batch size\n",
    "num_train_steps = int(len(train_features) / REPLICATION_FACTOR / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "assert REPLICATION_FACTOR == int(NUM_TRAIN_EPOCHS)\n",
    "\n",
    "print('num_train_steps', num_train_steps)\n",
    "\n",
    "# Skip this step to avoid disk quota\n",
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "run_config = tf.estimator.RunConfig(\n",
    "    model_dir=OUTPUT_DIR,\n",
    "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "  num_labels=len(label_list),\n",
    "  learning_rate=LEARNING_RATE,\n",
    "  num_train_steps=num_train_steps,\n",
    "  num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "estimator = tf.estimator.Estimator(\n",
    "  model_fn=model_fn,\n",
    "  config=run_config,\n",
    "  params={\"batch_size\": BATCH_SIZE})\n",
    "\n",
    "\n",
    "test_input_fn = run_classifier.input_fn_builder(\n",
    "    features=test_features,\n",
    "    seq_length=MAX_SEQ_LENGTH,\n",
    "    is_training=False,\n",
    "    drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_predictions(in_contexts, in_last_sentences):\n",
    "    input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = y, label = 0) for x, y in zip(in_contexts, in_last_sentences)] # here, \"\" is just a dummy label\n",
    "    input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
    "    predictions = estimator.predict(predict_input_fn)\n",
    "    predictions = [prediction['probabilities'] for prediction in predictions]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def combine_predictions(predictions):\n",
    "    my_predictions = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(test):\n",
    "        p_first = np.exp(predictions[i])\n",
    "        p_second = np.exp(predictions[i + 1])\n",
    "\n",
    "        p1 = p_first[0] + p_second[1]\n",
    "        p2 = p_first[1] + p_second[0]\n",
    "\n",
    "        if p1 > p2:\n",
    "            my_predictions.append(1)\n",
    "        else:\n",
    "            my_predictions.append(2)\n",
    "        i += 2\n",
    "        \n",
    "    return np.array(my_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= BEGINNING TRAINING FOR CLASSIFIER  0 =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/sanagnos/.local/lib64/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took time  0:07:11.910873\n",
      "Score on train is  1.0\n",
      "Score on val is  0.8840192410475681\n",
      "========= BEGINNING TRAINING FOR CLASSIFIER  1 =========\n",
      "Training took time  0:07:17.703832\n",
      "Score on train is  0.9994655264564404\n",
      "Score on val is  0.8813468733297701\n",
      "========= BEGINNING TRAINING FOR CLASSIFIER  2 =========\n",
      "Training took time  0:07:17.672840\n",
      "Score on train is  0.9994655264564404\n",
      "Score on val is  0.8797434526990914\n",
      "========= BEGINNING TRAINING FOR CLASSIFIER  3 =========\n",
      "Training took time  0:07:11.187757\n",
      "Score on train is  1.0\n",
      "Score on val is  0.8781400320684126\n",
      "========= BEGINNING TRAINING FOR CLASSIFIER  4 =========\n",
      "Training took time  0:07:11.733182\n",
      "Score on train is  1.0\n",
      "Score on val is  0.877605558524853\n",
      "========= BEGINNING TRAINING FOR CLASSIFIER  5 =========\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-1b45458d3828>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'========= BEGINNING TRAINING FOR CLASSIFIER {i:2d} ========='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_train_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training took time \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1205\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1239\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m   1240\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1241\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m   1242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1469\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1470\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    669\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1157\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1312\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!rm -rf {SAVE_RESULTS_DIR} || true\n",
    "!mkdir {SAVE_RESULTS_DIR}\n",
    "\n",
    "true_labels_train = train_unshuffled['class'].values[::2] + 1\n",
    "true_labels_val = test['class'].values[::2] + 1\n",
    "\n",
    "for i in range(N_ESTIMATORS):\n",
    "    !rm -rf {OUTPUT_DIR} || true\n",
    "    \n",
    "    train_features = shuffle(train_features)\n",
    "    \n",
    "    # Create an input function for training. drop_remainder = True for using TPUs.\n",
    "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "        features=train_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=True,\n",
    "        drop_remainder=False)\n",
    "\n",
    "    \n",
    "    print(f'========= BEGINNING TRAINING FOR CLASSIFIER {i:2d} =========')\n",
    "    current_time = datetime.now()\n",
    "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "\n",
    "    print(\"Training took time \", datetime.now() - current_time)\n",
    "        \n",
    "    predictions = get_final_predictions(train_unshuffled['story'].values, train_unshuffled['ending'].values)\n",
    "    print('Score on train is ', accuracy_score(true_labels_train, combine_predictions(predictions)))\n",
    "    np.savetxt(os.path.join(\"./\" + SAVE_RESULTS_DIR, \"predictions_train_\" + str(i) + '.csv'), predictions, delimiter=\",\")\n",
    "    \n",
    "    predictions = get_final_predictions(test['story'].values, test['ending'].values)\n",
    "    val_score = accuracy_score(true_labels_val, combine_predictions(predictions))\n",
    "    print('Score on val is ', val_score)\n",
    "    np.savetxt(os.path.join(\"./\" + SAVE_RESULTS_DIR, \"predictions_test_\" + str(val_score) + '_classifier_' + str(i) + '.csv'), predictions, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL 12 EPOCHS unlesss specified otherwise\n",
    "\n",
    "## just take pooled output from BERT:\n",
    "0.8562266167824693\n",
    "0.8722608230892571\n",
    "0.8583645109567076\n",
    "0.8599679315873864\n",
    "\n",
    "\n",
    "## only last sentece layers = [hidden_size]:\n",
    "0.8679850347407804\n",
    "0.8711918760021379\n",
    "0.877605558524853\n",
    "0.8765366114377339\n",
    "0.8674505611972207\n",
    "\n",
    "## same but for 3 epochs\n",
    "0.8760021378941742\n",
    "0.8722608230892571\n",
    "0.8743987172634955\n",
    "0.8797434526990914\n",
    "0.8797434526990914\n",
    "\n",
    "## only last sentece layers = [hidden_size * 5] 3 epochs:\n",
    "0.8813468733297701\n",
    "0.8818813468733298\n",
    "0.8733297701763763\n",
    "0.8808123997862106\n",
    "0.8733297701763763\n",
    "0.8738642437199359\n",
    "\n",
    "## only last sentece 3 epochs:[hidden_size * 5, hidden_size * 3, weight_size_last_sentence]\n",
    "0.8786745056119722\n",
    "0.8717263495456975\n",
    "\n",
    "## only last sentece layers = [hidden_size] 3 epochs with random_replacement 0.1:\n",
    "0.8850881881346874\n",
    "0.8743987172634955\n",
    "0.8685195082843399\n",
    "0.882950293960449\n",
    "0.8653126670229824\n",
    "\n",
    "## only last sentece layers = [hidden_size * 3] 3 epochs with random_replacement 0.2:\n",
    "0.8818813468733298\n",
    "0.8760021378941742\n",
    "0.882950293960449\n",
    "0.8808123997862106\n",
    "0.8743987172634955\n",
    "\n",
    "## only last sentece layers = [hidden_size * 3] 5 epochs with random_replacement 0.1:\n",
    "0.8695884553714591\n",
    "0.8647781934794228\n",
    "\n",
    "## only last sentece layers = [hidden_size * 3] 5 epochs with random_replacement 0.2:\n",
    "0.8840192410475681\n",
    "0.8813468733297701\n",
    "0.8797434526990914\n",
    "\n",
    "## concat of last sentence and context [hidden_size], [hidden_size] 3 epochs:\n",
    "0.8711918760021379\n",
    "0.8711918760021379\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 6. 9.]\n",
      " [2. 4. 6.]]\n",
      "[[2. 4. 6.]\n",
      " [3. 6. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# TEST \n",
    "\n",
    "mask = tf.constant([[0,0,1,1,1,0],\n",
    "                    [0,0,0,1,1,0]])\n",
    "\n",
    "mask1 = tf.constant([[1,1,1,1,1,0],\n",
    "                     [1,1,1,1,1,0]])\n",
    "\n",
    "\n",
    "features = tf.ones([2,6,3], dtype=tf.float32)\n",
    "\n",
    "# weights = tf.get_variable('weights', [3,3])\n",
    "weights = tf.constant([1,2,3], dtype=tf.float32)\n",
    "\n",
    "mask_expanded = tf.tile(tf.expand_dims(mask, 2), [1,1,3])\n",
    "mask_expanded = tf.cast(mask_expanded, tf.float32)\n",
    "r = (features * weights) * mask_expanded\n",
    "\n",
    "r = tf.reduce_sum(r, 1)\n",
    "\n",
    "mask_expanded1 = tf.tile(tf.expand_dims((mask1 * (1 - mask)), 2), [1,1,3])\n",
    "mask_expanded1 = tf.cast(mask_expanded1, tf.float32)\n",
    "r1 = (features * weights) * mask_expanded1\n",
    "\n",
    "r1 = tf.reduce_sum(r1, 1)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(r))\n",
    "    print(sess.run(r1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For classifier  0 test accuracy 0.9033\n",
      "For classifier  1 test accuracy 0.9017\n",
      "For classifier  2 test accuracy 0.8947\n",
      "For classifier  3 test accuracy 0.8979\n",
      "For classifier  4 test accuracy 0.9043\n",
      "For classifier  5 test accuracy 0.9081\n",
      "For classifier  6 test accuracy 0.9086\n",
      "For classifier  7 test accuracy 0.9065\n",
      "For classifier  8 test accuracy 0.8872\n",
      "For classifier  9 test accuracy 0.8947\n",
      "For classifier 10 test accuracy 0.8936\n",
      "For classifier 11 test accuracy 0.8990\n",
      "For classifier 12 test accuracy 0.9027\n",
      "For classifier 14 test accuracy 0.9054\n",
      "ENSEMBLE ACCURACY MODE\n",
      "0.9182255478353821\n",
      "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
      "0.9198289684660609\n",
      "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
      "0.9192944949225014\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "SAVE_RESULTS_DIR = 'results_predictions'\n",
    "\n",
    "\n",
    "files = [f for f in listdir(SAVE_RESULTS_DIR) if isfile(join(SAVE_RESULTS_DIR, f))]\n",
    "\n",
    "true_labels_train = train_unshuffled['class'].values[::2] + 1\n",
    "true_labels_test = test['class'].values[::2] + 1\n",
    "\n",
    "classifiers = [int(file.split(\"_\")[4].split(\".\")[0]) for file in files]\n",
    "num_classifiers = np.max(classifiers)\n",
    "\n",
    "predictions_train = []\n",
    "predictions_test = []\n",
    "for i in range(num_classifiers + 1):\n",
    "#     predictions_file_train = np.genfromtxt(os.path.join(\"./\" + SAVE_RESULTS_DIR, \n",
    "#                                                         \"predictions_train_\" + str(i) + '.csv'), delimiter=',')\n",
    "#     predictions_train.append(predictions_file_train)\n",
    "    \n",
    "    test_file = [x for x in files if 'classifier_' + str(i) in x][0]\n",
    "    predictions_file_test = np.genfromtxt(os.path.join(\"./\" + SAVE_RESULTS_DIR, test_file), delimiter=',')\n",
    "    predictions_test.append(predictions_file_test)\n",
    "#     print(f'For classifier {i:2d} train accuracy {accuracy_score(true_labels_train, combine_predictions(predictions_file_train)):.4f} and test accuracy {accuracy_score(true_labels_test, combine_predictions(predictions_file_test)):.4f}')\n",
    "    print(f'For classifier {i:2d} test accuracy {accuracy_score(true_labels_test, combine_predictions(predictions_file_test)):.4f}')\n",
    "    \n",
    "def print_ensemble_predictions(predictions, true_labels):\n",
    "    preds_mode = [combine_predictions(p) for p in predictions]\n",
    "    preds_mode = np.array(preds_mode)\n",
    "    preds_mode = stats.mode(preds_mode)[0][0]\n",
    "\n",
    "    print('ENSEMBLE ACCURACY MODE')\n",
    "    print(accuracy_score(true_labels, preds_mode))\n",
    "\n",
    "    preds_prob = np.mean(predictions, axis=0)\n",
    "    preds_prob = combine_predictions(preds_prob)\n",
    "\n",
    "    print('ENSEMBLE ACCURACY PROB MEAN ON LOGS')\n",
    "    print(accuracy_score(true_labels, preds_prob))\n",
    "\n",
    "\n",
    "    preds_prob = np.log(np.mean(np.exp(predictions), axis=0))\n",
    "    preds_prob = combine_predictions(preds_prob)\n",
    "\n",
    "    print('ENSEMBLE ACCURACY PROB MEAN ON PROBS')\n",
    "    print(accuracy_score(true_labels, preds_prob))\n",
    "    print()\n",
    "    \n",
    "    \n",
    "# print_ensemble_predictions(predictions_train, true_labels_train)\n",
    "print_ensemble_predictions(predictions_test, true_labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.85567284, -0.55338029],\n",
       "       [-0.87034223, -0.54267442],\n",
       "       [-0.60520196, -0.78957908],\n",
       "       ...,\n",
       "       [-1.29842089, -0.31877721],\n",
       "       [-1.00223294, -0.4573779 ],\n",
       "       [-0.17982265, -1.80434856]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### OLD\n",
    "\n",
    "\n",
    "small_bert (whole val and whole test)\n",
    "\n",
    "output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "logits = tf.layers.dense(output_layer, 128, use_bias=True, activation=tf.nn.sigmoid)\n",
    "logits = tf.nn.dropout(logits, keep_prob=0.9)\n",
    "logits = tf.layers.dense(logits, num_labels, use_bias=True)\n",
    "\n",
    "For classifier  0 train accuracy 1.0000 and test accuracy 0.8391\n",
    "For classifier  1 train accuracy 1.0000 and test accuracy 0.8343\n",
    "For classifier  2 train accuracy 1.0000 and test accuracy 0.8386\n",
    "For classifier  3 train accuracy 1.0000 and test accuracy 0.8311\n",
    "For classifier  4 train accuracy 1.0000 and test accuracy 0.8434\n",
    "For classifier  5 train accuracy 1.0000 and test accuracy 0.8397\n",
    "For classifier  6 train accuracy 1.0000 and test accuracy 0.8434\n",
    "For classifier  7 train accuracy 1.0000 and test accuracy 0.8418\n",
    "For classifier  8 train accuracy 1.0000 and test accuracy 0.8359\n",
    "For classifier  9 train accuracy 1.0000 and test accuracy 0.8487\n",
    "For classifier 10 train accuracy 1.0000 and test accuracy 0.8332\n",
    "For classifier 11 train accuracy 1.0000 and test accuracy 0.8429\n",
    "For classifier 12 train accuracy 1.0000 and test accuracy 0.8397\n",
    "For classifier 13 train accuracy 1.0000 and test accuracy 0.8407\n",
    "For classifier 14 train accuracy 1.0000 and test accuracy 0.8365\n",
    "ENSEMBLE ACCURACY MODE\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "1.0\n",
    "\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.8722608230892571\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.8786745056119722\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.8786745056119722\n",
    "\n",
    "big_bert (whole val and whole test)\n",
    "For classifier  0 train accuracy 1.0000 and test accuracy 0.8691\n",
    "For classifier  1 train accuracy 1.0000 and test accuracy 0.8664\n",
    "For classifier  2 train accuracy 1.0000 and test accuracy 0.8680\n",
    "For classifier  3 train accuracy 1.0000 and test accuracy 0.8562\n",
    "For classifier  4 train accuracy 0.9984 and test accuracy 0.8397\n",
    "For classifier  5 train accuracy 1.0000 and test accuracy 0.8696\n",
    "For classifier  6 train accuracy 1.0000 and test accuracy 0.8381\n",
    "For classifier  7 train accuracy 1.0000 and test accuracy 0.8589\n",
    "For classifier  8 train accuracy 1.0000 and test accuracy 0.8632\n",
    "For classifier  9 train accuracy 1.0000 and test accuracy 0.8600\n",
    "For classifier 10 train accuracy 1.0000 and test accuracy 0.8701\n",
    "For classifier 11 train accuracy 1.0000 and test accuracy 0.8696\n",
    "For classifier 12 train accuracy 0.9947 and test accuracy 0.8268\n",
    "For classifier 13 train accuracy 1.0000 and test accuracy 0.8653\n",
    "For classifier 14 train accuracy 0.9995 and test accuracy 0.8044\n",
    "ENSEMBLE ACCURACY MODE\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "1.0\n",
    "\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.8979155531801176\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9021913415285944\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.8984500267236771\n",
    "\n",
    "big bert [512]\n",
    "\n",
    "For classifier  0 train accuracy 1.0000 and test accuracy 0.8792\n",
    "For classifier  1 train accuracy 1.0000 and test accuracy 0.8787\n",
    "For classifier  2 train accuracy 0.9989 and test accuracy 0.8952\n",
    "For classifier  3 train accuracy 1.0000 and test accuracy 0.8803\n",
    "For classifier  4 train accuracy 1.0000 and test accuracy 0.8632\n",
    "For classifier  5 train accuracy 1.0000 and test accuracy 0.8717\n",
    "For classifier  6 train accuracy 1.0000 and test accuracy 0.8797\n",
    "For classifier  7 train accuracy 1.0000 and test accuracy 0.8733\n",
    "For classifier  8 train accuracy 1.0000 and test accuracy 0.8781\n",
    "For classifier  9 train accuracy 1.0000 and test accuracy 0.8712\n",
    "For classifier 10 train accuracy 1.0000 and test accuracy 0.8616\n",
    "For classifier 11 train accuracy 1.0000 and test accuracy 0.8669\n",
    "For classifier 12 train accuracy 0.9995 and test accuracy 0.8589\n",
    "For classifier 13 train accuracy 1.0000 and test accuracy 0.8632\n",
    "For classifier 14 train accuracy 1.0000 and test accuracy 0.8803\n",
    "ENSEMBLE ACCURACY MODE\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "1.0\n",
    "\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.9048637092463923\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9075360769641903\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.9048637092463923\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "one weight [hidden_size, hidden_size] all between first_sep_token and first_pad_token (15 epochs)\n",
    "\n",
    "For classifier  0 train accuracy 1.0000 and test accuracy 0.8787\n",
    "For classifier  1 train accuracy 1.0000 and test accuracy 0.8899\n",
    "For classifier  2 train accuracy 1.0000 and test accuracy 0.8867\n",
    "For classifier  3 train accuracy 1.0000 and test accuracy 0.8771\n",
    "For classifier  4 train accuracy 0.9995 and test accuracy 0.8904\n",
    "For classifier  5 train accuracy 1.0000 and test accuracy 0.8883\n",
    "For classifier  6 train accuracy 1.0000 and test accuracy 0.8856\n",
    "For classifier  7 train accuracy 1.0000 and test accuracy 0.8840\n",
    "For classifier  8 train accuracy 1.0000 and test accuracy 0.8830\n",
    "For classifier  9 train accuracy 1.0000 and test accuracy 0.8942\n",
    "For classifier 10 train accuracy 1.0000 and test accuracy 0.8985\n",
    "For classifier 11 train accuracy 1.0000 and test accuracy 0.8910\n",
    "For classifier 12 train accuracy 1.0000 and test accuracy 0.8936\n",
    "For classifier 13 train accuracy 1.0000 and test accuracy 0.8936\n",
    "For classifier 14 train accuracy 1.0000 and test accuracy 0.8862\n",
    "ENSEMBLE ACCURACY MODE\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "1.0\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "1.0\n",
    "\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.9102084446819882\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9064671298770711\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.9075360769641903\n",
    "\n",
    "---------------------------------------------------------------------------------\n",
    "replace words 0.2 only last sentece layers = [hidden_size * 3] 5 epochs\n",
    "\n",
    "For classifier  0 test accuracy 0.8872\n",
    "For classifier  1 test accuracy 0.8915\n",
    "For classifier  2 test accuracy 0.9017\n",
    "For classifier  3 test accuracy 0.8968\n",
    "For classifier  4 test accuracy 0.8958\n",
    "For classifier  6 test accuracy 0.8936\n",
    "For classifier  7 test accuracy 0.8936\n",
    "For classifier  8 test accuracy 0.9027\n",
    "For classifier  9 test accuracy 0.8920\n",
    "For classifier 10 test accuracy 0.8947\n",
    "For classifier 11 test accuracy 0.8958\n",
    "For classifier 12 test accuracy 0.8968\n",
    "For classifier 13 test accuracy 0.9033\n",
    "For classifier 14 test accuracy 0.8824\n",
    "For classifier 15 test accuracy 0.8990\n",
    "For classifier 16 test accuracy 0.9022\n",
    "For classifier 17 test accuracy 0.8931\n",
    "For classifier 18 test accuracy 0.8958\n",
    "For classifier 19 test accuracy 0.8867\n",
    "For classifier 20 test accuracy 0.9006\n",
    "For classifier 21 test accuracy 0.8936\n",
    "For classifier 22 test accuracy 0.8985\n",
    "For classifier 23 test accuracy 0.8931\n",
    "For classifier 24 test accuracy 0.9001\n",
    "For classifier 25 test accuracy 0.8920\n",
    "For classifier 26 test accuracy 0.9017\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.914484233030465\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9139497594869054\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.9134152859433458\n",
    "\n",
    "---------------------------------------------------------------------------------\n",
    "replace words 0.2 bidirectional lstm only last sentence num_layers=1 hidden_size=hidden_size\n",
    "\n",
    "For classifier  0 test accuracy 0.8899\n",
    "For classifier  1 test accuracy 0.8936\n",
    "For classifier  2 test accuracy 0.8920\n",
    "For classifier  3 test accuracy 0.8985\n",
    "For classifier  4 test accuracy 0.8846\n",
    "For classifier  5 test accuracy 0.8931\n",
    "For classifier  6 test accuracy 0.9027\n",
    "For classifier  7 test accuracy 0.8958\n",
    "For classifier  8 test accuracy 0.9017\n",
    "For classifier  9 test accuracy 0.9118\n",
    "For classifier 10 test accuracy 0.9033\n",
    "For classifier 11 test accuracy 0.9038\n",
    "For classifier 12 test accuracy 0.8963\n",
    "For classifier 13 test accuracy 0.8942\n",
    "For classifier 14 test accuracy 0.8867\n",
    "For classifier 15 test accuracy 0.8952\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.9155531801175841\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.911811865312667\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.911811865312667\n",
    "\n",
    "---------------------------------------------------------------------------------\n",
    "replace words 0.2 bidirectional gru only last sentence num_layers=1 hidden_size=hidden_size\n",
    "\n",
    "For classifier  0 test accuracy 0.8947\n",
    "For classifier  1 test accuracy 0.9065\n",
    "For classifier  2 test accuracy 0.9118\n",
    "For classifier  3 test accuracy 0.8958\n",
    "For classifier  4 test accuracy 0.8936\n",
    "For classifier  5 test accuracy 0.8920\n",
    "For classifier  6 test accuracy 0.9006\n",
    "For classifier  7 test accuracy 0.8958\n",
    "For classifier  8 test accuracy 0.9022\n",
    "For classifier  9 test accuracy 0.8926\n",
    "For classifier 10 test accuracy 0.9033\n",
    "For classifier 11 test accuracy 0.8840\n",
    "For classifier 12 test accuracy 0.8904\n",
    "For classifier 14 test accuracy 0.8974\n",
    "For classifier 15 test accuracy 0.8947\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.911811865312667\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9128808123997862\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.914484233030465\n",
    "\n",
    "--------------------------------------------------------------------------\n",
    "conv2d [5,5] [5,5]\n",
    "\n",
    "For classifier  0 test accuracy 0.9033\n",
    "For classifier  1 test accuracy 0.9017\n",
    "For classifier  2 test accuracy 0.8947\n",
    "For classifier  3 test accuracy 0.8979\n",
    "For classifier  4 test accuracy 0.9043\n",
    "For classifier  5 test accuracy 0.9081\n",
    "For classifier  6 test accuracy 0.9086\n",
    "For classifier  7 test accuracy 0.9065\n",
    "For classifier  8 test accuracy 0.8872\n",
    "For classifier  9 test accuracy 0.8947\n",
    "For classifier 10 test accuracy 0.8936\n",
    "For classifier 11 test accuracy 0.8990\n",
    "For classifier 12 test accuracy 0.9027\n",
    "For classifier 13 test accuracy 0.5168\n",
    "For classifier 14 test accuracy 0.9054\n",
    "ENSEMBLE ACCURACY MODE\n",
    "0.9203634420096205\n",
    "ENSEMBLE ACCURACY PROB MEAN ON LOGS\n",
    "0.9182255478353821\n",
    "ENSEMBLE ACCURACY PROB MEAN ON PROBS\n",
    "0.9203634420096205"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
