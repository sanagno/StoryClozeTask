{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/apps/python/3.6.4/lib64/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0522 18:08:35.359369 47033619180992 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.utils import get_final_predictions, load_embedding\n",
    "from src.data import DataProcessing\n",
    "import tensorflow as tf\n",
    "import src.data as my_data\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)  # suppress some deprecation warnings\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_processing = DataProcessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = './data/'\n",
    "\n",
    "data_processing.train_data, data_processing.train_classes = \\\n",
    "        data_processing.read_data_train(os.path.join(data_directory, 'train_stories.csv'))\n",
    "data_processing.val_data, data_processing.val_classes = \\\n",
    "    data_processing.read_data_val(os.path.join(data_directory,\n",
    "                                               'cloze_test_val__spring2016 - cloze_test_ALL_val.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total distinct tokens found: 17268\n",
      "vocabulary_size 17270\n"
     ]
    }
   ],
   "source": [
    "data_processing.construct_vocab()\n",
    "\n",
    "print('vocabulary_size', len(data_processing.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "embedding_size = 300\n",
    "\n",
    "units = 1024\n",
    "num_labels = 2\n",
    "NUM_EPOCHS = 2\n",
    "NEGATIVE_SAMPLING = 3\n",
    "\n",
    "NUM_SAMPLES_TRAINING = data_processing.num_samples_training\n",
    "NUM_SAMPLES_VALIDATION = data_processing.num_samples_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_context, train_last_sentence, train_y = data_processing.create_dataset(0, BATCH_SIZE, NEGATIVE_SAMPLING)\n",
    "\n",
    "test_context, test_last_sentence, test_y = data_processing.create_dataset(1, BATCH_SIZE, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext:0\", shape=(?, 80), dtype=int32)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 20), dtype=int32)\n",
      "Tensor(\"IteratorGetNext:2\", shape=(?,), dtype=int32)\n",
      "\n",
      "Tensor(\"IteratorGetNext_1:0\", shape=(?, 80), dtype=int32)\n",
      "Tensor(\"IteratorGetNext_1:1\", shape=(?, 20), dtype=int32)\n",
      "Tensor(\"IteratorGetNext_1:2\", shape=(?,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(train_context)\n",
    "print(train_last_sentence)\n",
    "print(train_y)\n",
    "print()\n",
    "print(test_context)\n",
    "print(test_last_sentence)\n",
    "print(test_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, enc_units):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.enc_units = enc_units\n",
    "        \n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self, batch_size):\n",
    "        return tf.zeros((batch_size, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        \n",
    "        self.W1 = tf.keras.layers.Dense(units, name='Dense_1')\n",
    "        self.W2 = tf.keras.layers.Dense(units, name='Dense_2')\n",
    "        self.V = tf.keras.layers.Dense(1, name='Dense_3')\n",
    "    \n",
    "    def call(self, query, values):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, hidden_size)\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayerWithSoftmax(tf.keras.Model):\n",
    "    def __init__(self, layers, num_classes, dropout_keep_proba=0.9, activation=tf.nn.relu):\n",
    "        super(DenseLayerWithSoftmax, self).__init__()\n",
    "        \n",
    "        self.dense_layers = []\n",
    "        self.dropout_keep_proba = dropout_keep_proba\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        for i, layer_size in enumerate(layers):\n",
    "            self.dense_layers.append(tf.keras.layers.Dense(layer_size, name='DenseLayer_' + str(i), use_bias=True, activation=tf.nn.relu))\n",
    "    \n",
    "        self.final_layer = tf.keras.layers.Dense(self.num_classes, name='DenseLayer_final', use_bias=True)\n",
    "    \n",
    "    def call(self, input_, input_labels):\n",
    "        \n",
    "        logits = input_\n",
    "        \n",
    "        for layer in self.dense_layers:\n",
    "            logits = layer(logits)\n",
    "            logits = tf.nn.dropout(logits, keep_prob=self.dropout_keep_proba)\n",
    "\n",
    "        logits = self.final_layer(logits)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(input_labels, depth=self.num_classes, dtype=tf.float32)\n",
    "        \n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "\n",
    "        per_example_loss = - tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        \n",
    "        return predicted_labels, loss, log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(name, shape, initializer=tf.contrib.layers.xavier_initializer()):\n",
    "    \"\"\"\n",
    "    Creates a variable with a specified initializer\n",
    "    \"\"\"\n",
    "    variable = tf.get_variable(name, initializer=initializer(shape))\n",
    "    return variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSDSem 2017: Exploring Data Generation Methods for the Story Cloze Test (https://aclweb.org/anthology/W17-0908)\n",
    "\n",
    "Separate networks for encoder and decoder. Concatenate their states and feed forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoRNNSConcatOutputs(tf.keras.Model):\n",
    "    def __init__(self, units, vocabulary_size, num_classes=2,\n",
    "                 fc_layers=[], dropout_keep_proba=0.9, activation=tf.nn.relu):\n",
    "        super(TwoRNNSConcatOutputs, self).__init__()\n",
    "        \n",
    "        self.units = units\n",
    "        \n",
    "        self.input_embeddings = weight_variable('input_embeddings', [vocabulary_size, embedding_size])\n",
    "        \n",
    "        self.encoder = Encoder(self.units)\n",
    "        self.decoder = Encoder(self.units)\n",
    "        \n",
    "        self.feed_foward = DenseLayerWithSoftmax(fc_layers, num_classes, \n",
    "                                                 dropout_keep_proba=dropout_keep_proba, activation=activation)\n",
    "        \n",
    "    def call(self, input_context, input_last_sentence, input_labels):\n",
    "\n",
    "        context_embedding = tf.nn.embedding_lookup(self.input_embeddings, input_context,\n",
    "                                                   name='sentence_embedding')\n",
    "        \n",
    "        last_sentence_embedding = tf.nn.embedding_lookup(self.input_embeddings, input_last_sentence,\n",
    "                                                   name='sentence_embedding')\n",
    "        \n",
    "        # pass through encoder\n",
    "        sample_hidden_enc = self.encoder.initialize_hidden_state(tf.shape(context_embedding)[0])\n",
    "        sample_output_enc, sample_hidden_enc = self.encoder(context_embedding, sample_hidden_enc)\n",
    "        \n",
    "        # pass through decoder \n",
    "#         sample_hidden_dec = self.decoder.initialize_hidden_state(tf.shape(last_sentence_embedding)[0])\n",
    "        sample_output_dec, sample_hidden_dec = self.decoder(last_sentence_embedding, sample_hidden_enc)\n",
    "        \n",
    "        # concatenate last two states\n",
    "        concatenated_outputs = tf.concat([sample_hidden_enc, sample_hidden_dec], axis=1)\n",
    "        \n",
    "        return self.feed_foward(concatenated_outputs, input_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_layers = [128]\n",
    "\n",
    "vocabulary_size = len(data_processing.vocab)\n",
    "\n",
    "twoRNNSConcatOutputs = TwoRNNSConcatOutputs(units, vocabulary_size, num_classes=2, fc_layers=[])\n",
    "\n",
    "predicted_labels_train, loss_train, log_probs_train = twoRNNSConcatOutputs(train_context, train_last_sentence, train_y)\n",
    "predicted_labels_test, loss_test, log_probs_test = twoRNNSConcatOutputs(test_context, test_last_sentence, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MY attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyAttention(tf.keras.Model):\n",
    "#     def __init__(self, units, attention_units=10, num_classes=2, fc_layers=[], dropout_keep_proba=0.9, activation=tf.nn.relu):\n",
    "#         super(AttentionRNN, self).__init__()\n",
    "        \n",
    "#         self.units = units\n",
    "        \n",
    "#         self.input_embeddings = weight_variable('input_embeddings', [vocabulary_size, embedding_size])\n",
    "        \n",
    "#         self.encoder = Encoder(self.units)\n",
    "#         self.decoder = Encoder(self.units)\n",
    "        \n",
    "#         self.attention_layer = BahdanauAttention(attention_units)\n",
    "#         self.feed_foward = DenseLayerWithSoftmax(fc_layers, num_classes, \n",
    "#                                                  dropout_keep_proba=dropout_keep_proba, activation=activation)\n",
    "        \n",
    "#     def call(self, input_context, input_last_sentence, input_labels):\n",
    "\n",
    "#         context_embedding = tf.nn.embedding_lookup(self.input_embeddings, input_context,\n",
    "#                                                    name='sentence_embedding')\n",
    "        \n",
    "#         last_sentence_embedding = tf.nn.embedding_lookup(self.input_embeddings, input_last_sentence,\n",
    "#                                                    name='sentence_embedding')\n",
    "#         # sample input\n",
    "#         sample_hidden = self.encoder.initialize_hidden_state(tf.shape(story_embedding)[0])\n",
    "#         sample_output, sample_hidden = self.encoder(story_embedding, sample_hidden)\n",
    "        \n",
    "#         sentence_to_check = tf.reshape(sample_output[:, -1, :], [-1, self.units])\n",
    "#         first_four_sentences = sample_output[:, :4, :]\n",
    "        \n",
    "#         attention_result, attention_weights = self.attention_layer(sentence_to_check, first_four_sentences)\n",
    "        \n",
    "#         return self.feed_foward(attention_result, input_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "551\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "update_lr_every = int((math.ceil(NUM_SAMPLES_TRAINING / (BATCH_SIZE / (NEGATIVE_SAMPLING + 1))) * NUM_EPOCHS) / 20)\n",
    "\n",
    "global_step  = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "print(update_lr_every)\n",
    "\n",
    "# learning rate 1e-3 for most models\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "  2e-4,                 # Base learning rate.\n",
    "  global_step,  # Current index into the dataset.\n",
    "  update_lr_every,          # Decay step.\n",
    "  0.96,                # Decay rate.\n",
    "  staircase=True)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "gradients, variables = zip(*optimizer.compute_gradients(loss_train))\n",
    "gradients, _ = tf.clip_by_global_norm(gradients, 5.0)\n",
    "train_op = optimizer.apply_gradients(zip(gradients, variables), global_step=global_step)\n",
    "\n",
    "# train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss_train, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove model\n",
      "Done. 400000  words loaded!\n",
      "<unk> not in embedding file\n",
      "<pad> not in embedding file\n",
      "hadn not in embedding file\n",
      "00pm not in embedding file\n",
      "17266 words out of 17270 could be loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training phase            :  30%|███       | 3330/11022 [28:57<1:06:04,  1.94it/s, epoch=0, iter_percent=60 %]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-8ab8d274341b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch_cur\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miter_percent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%d %%\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_cur\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNUM_SAMPLES_TRAINING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib64/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "import math\n",
    "import sys\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    load_embedding(sess, data_processing.vocab, twoRNNSConcatOutputs.input_embeddings,\n",
    "                   '/cluster/project/infk/courses/machine_perception_19/Sasglentamekaiedo/glove.6B.300d.txt',\n",
    "                   embedding_size)\n",
    "#                    embedding_size, len(data_processing.vocab))\n",
    "    \n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    def get_predictions(predicted_labels, y, log_probs, number_of_steps, num_samples, phase):\n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "        log_probs_total = []\n",
    "        \n",
    "        desc = 'predictions on ' + str(phase)\n",
    "        desc = desc.ljust(26)\n",
    "        with trange(number_of_steps, desc=desc) as t:\n",
    "            for i in t:\n",
    "                # display training status\n",
    "                epoch_cur = i * BATCH_SIZE // num_samples\n",
    "                iter_cur = (i * BATCH_SIZE ) % num_samples\n",
    "                t.set_postfix(epoch=epoch_cur,iter_percent=\"%d %%\"%(iter_cur/float(NUM_SAMPLES_VALIDATION)*100) )\n",
    "                \n",
    "                predictions_batch, true_labels_batch, log_probs_batch = sess.run([predicted_labels, y, log_probs])\n",
    "\n",
    "                predictions.append(predictions_batch)\n",
    "                true_labels.append(true_labels_batch)\n",
    "                log_probs_total.append(log_probs_batch)\n",
    "        \n",
    "        return np.concatenate(predictions, axis=0).reshape(-1), np.concatenate(true_labels, axis=0).reshape(-1), \\\n",
    "                    np.concatenate(log_probs_total, axis=0).reshape(-1, 2)\n",
    "    \n",
    "#     with trange(math.ceil(NUM_SAMPLES_TRAINING / (BATCH_SIZE / (NEGATIVE_SAMPLING + 1))) * NUM_EPOCHS) as t:\n",
    "#     if train_on_validation:\n",
    "#         number_of_steps = math.ceil(NUM_SAMPLES_TRAINING / BATCH_SIZE)\n",
    "#         batch_index = BATCH_SIZE \n",
    "#     else:\n",
    "    number_of_steps = math.ceil(NUM_SAMPLES_TRAINING / (BATCH_SIZE / (NEGATIVE_SAMPLING + 1)))\n",
    "    batch_index = BATCH_SIZE / (NEGATIVE_SAMPLING + 1)\n",
    "\n",
    "    desc = 'training phase'.ljust(26)\n",
    "    with trange(number_of_steps * NUM_EPOCHS, desc=desc) as t:\n",
    "        last_epoch = 0\n",
    "        for i in t:\n",
    "            # display training status\n",
    "            epoch_cur = (i * batch_index) // NUM_SAMPLES_TRAINING\n",
    "            iter_cur = (i * batch_index) % NUM_SAMPLES_TRAINING\n",
    "            t.set_postfix(epoch=epoch_cur,iter_percent=\"%d %%\"%(iter_cur/float(NUM_SAMPLES_TRAINING)*100) )\n",
    "            \n",
    "            _, _, lt = sess.run([train_op, global_step, loss_train])\n",
    "\n",
    "            losses.append(lt)\n",
    "             \n",
    "            if epoch_cur > last_epoch:\n",
    "                last_epoch = epoch_cur\n",
    "                predictions_test, labels_test, probabilities_test = get_predictions(predicted_labels_test, test_y, log_probs_test, math.ceil(NUM_SAMPLES_VALIDATION / BATCH_SIZE), NUM_SAMPLES_VALIDATION, 'validation')\n",
    "                print(f'Raw predictions validation score {accuracy_score(labels_test, predictions_test):.3f} and unified {accuracy_score(labels_test[::2], get_final_predictions(probabilities_test, threshold=1)):.3f}')\n",
    "            \n",
    "    predictions_train, labels_train, probabilities_train = get_predictions(predicted_labels_train, train_y, log_probs_train, number_of_steps, NUM_SAMPLES_TRAINING, 'training')\n",
    "    predictions_test, labels_test, probabilities_test = get_predictions(predicted_labels_test, test_y, log_probs_test, math.ceil(NUM_SAMPLES_VALIDATION / BATCH_SIZE), NUM_SAMPLES_VALIDATION, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2ac79fd66588>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAAEyCAYAAACyDpLjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xe8k+X9//H3JzmLcdh7o4CIA9QjuBBQRED90mGto1qtFm21tWrtT1tXtf1K7be2tdW6aqm1aq17IqIIbpbsedgcxjnMs1dy/f7IIDknh5MDyTnk8Ho+OI+T3CtXcieHvO9rmXNOAAAAAIDU42nqAgAAAAAADg6BDgAAAABSFIEOAAAAAFIUgQ4AAAAAUhSBDgAAAABSFIEOAAAAAFIUgQ4AAAAAUhSBDgAAAABSVL2Bzsx6m9lMM1tuZsvM7OYY21xhZovNbImZfW5mQyPWbQguX2hm8xL9BAAAAADgSJUWxzbVkm5zzi0ws2xJ883sA+fc8oht1ksa5ZzbY2YTJD0paUTE+jHOuZ3xFqpTp06uX79+8W4OAAAAAM3K/PnzdzrnOte3Xb2Bzjm3TdK24O0iM1shqaek5RHbfB6xy5eSejW4xBH69eunefOozAMAAABwZDKzjfFs16A+dGbWT9JJkr46wGbXSnov4r6TNMPM5pvZ5AMce7KZzTOzeQUFBQ0pFgAAAAAckeJpcilJMrPWkl6R9DPnXGEd24xRINCdFbH4LOdcnpl1kfSBma10zs2uua9z7kkFmmoqJyfHNeA5AAAAAMARKa4aOjNLVyDM/ds592od25wo6WlJk5xzu0LLnXN5wd/5kl6TNPxQCw0AAAAAiG+US5P0d0krnHMP17FNH0mvSrrSObc6Ynmr4EAqMrNWksZJWpqIggMAAADAkS6eJpdnSrpS0hIzWxhc9ktJfSTJOfe4pHskdZT0WCD/qdo5lyOpq6TXgsvSJD3vnJuW0GcAAAAAAEeoeEa5/FSS1bPNdZKui7F8naShtfcAAAAAAByqBo1yCQAAAAA4fBDoAAAAACBFEegAAAAAIEUR6AAAjWbz7lKtLShu6mIAANBsxD2xOAAAh2rkQzMlSRumXNDEJQEAoHmghg4AAAAAUhSBDgAAAABSFIEOAAAAAFIUgQ4AAAAAUhSBDgAAAABSFIEOAAAAAFIUgQ4AAAAAUhSBDgAAAABSFIEOAAAAAFIUgQ4AAAAAUhSBDgAAAABSFIEOAAAAAFIUgQ4AAAAAUhSBDgAAAABSFIEOAAAAAFIUgQ4AAAAAUhSBDgAAAABSFIEOAAAAAFIUgQ4AAAAAUhSBDgAAAABSFIEOAAAAAFIUgQ4AAAAAUlS9gc7MepvZTDNbbmbLzOzmGNuYmT1iZrlmttjMTo5YN97MVgXX3ZHoJwAAAAAAR6p4auiqJd3mnBsi6TRJN5rZkBrbTJA0MPgzWdLfJMnMvJIeDa4fIumyGPsCAAAAAA5CvYHOObfNObcgeLtI0gpJPWtsNknSsy7gS0ntzKy7pOGScp1z65xzlZJeDG4LAAAAADhEDepDZ2b9JJ0k6asaq3pK2hxxf0twWV3LYx17spnNM7N5BQUFDSkWAAAAAByR4g50ZtZa0iuSfuacK0x0QZxzTzrncpxzOZ07d0704QEAAACg2UmLZyMzS1cgzP3bOfdqjE3yJPWOuN8ruCy9juUAAAAAgEMUzyiXJunvklY45x6uY7M3JV0VHO3yNEn7nHPbJM2VNNDM+ptZhqRLg9sCAAAAAA5RPDV0Z0q6UtISM1sYXPZLSX0kyTn3uKR3JU2UlCupVNI1wXXVZnaTpPcleSU945xbltBnAAAAAABHqHoDnXPuU0lWzzZO0o11rHtXgcAHAAAAAEigBo1yCQAAAAA4fBDoAAAAACBFEegAAAAAIEUR6AAAAAAgRRHoAAAAACBFEegAAAAAIEUR6AAAAAAgRRHoAAAAACBFEegAAAAAIEUR6AAAAAAgRRHoAAAAACBFEegAAAAAIEUR6AAAAAAgRRHoAAAAACBFEegAAI3COdfURQAAoNkh0AEAGsWTs9c1dREAAGh2CHQAgEbx7pJtTV0EAACaHQIdAKDRzVi+o6mLAABAs0CgAwA0usV5+5q6CAAANAsEOgBAo2BIFAAAEo9ABwBoFAxyCQBA4hHoAACNwkXW0ZHuAABICAIdAAAAAKQoAh0AoPGZNXUJAABoFgh0AIBGQStLAAASj0AHAGgUBDoAABKPQAcAaHykOwAAEiKtvg3M7BlJF0rKd84dH2P97ZKuiDjesZI6O+d2m9kGSUWSfJKqnXM5iSo4ACC1EOEAAEi8eGropkoaX9dK59zvnXPDnHPDJN0paZZzbnfEJmOC6wlzAHAEc9TKAQCQcPUGOufcbEm769su6DJJLxxSiQAAAAAAcUlYHzoza6lATd4rEYudpBlmNt/MJtez/2Qzm2dm8woKChJVLADAYYIKOgAAEi+Rg6JcJOmzGs0tzwo2xZwg6UYzO7uunZ1zTzrncpxzOZ07d05gsQAAhwNHLzoAABIukYHuUtVobumcywv+zpf0mqThCXw8AEAK8UfmOSYWBwAgIRIS6MysraRRkt6IWNbKzLJDtyWNk7Q0EY8HAEg9UYOi0P4SAICEiGfaghckjZbUycy2SLpXUrokOeceD272TUnTnXMlEbt2lfSaBa7Cpkl63jk3LXFFBwCkEiIcAACJV2+gc85dFsc2UxWY3iBy2TpJQw+2YACAZoZEBwBAwiWyDx0AAAAAoBER6AAAjcJPvzkAABKOQAcAaBTEOQAAEo9ABwBoFFTQAQCQeAQ6AECjYGJxAAASj0AHAGgU1NABAJB4BDoAQKMg0AEAkHgEOgAAAABIUQQ6AECjcFTRAQCQcAQ6AECjIM4BAJB4BDoAQKOggg4AgMQj0AEAGgXTFgAAkHgEOgBAo6CGDgCAxCPQAQAaBXkOAIDEI9ABABoFo1wCAJB4BDoAQKMgzwEAkHgEOgAAAABIUQQ6AEDS/ei5+dpVUtnUxQAAoNkh0AEAku69pdubuggAADRLBDoAAAAASFEEOgAAAABIUQQ6AEBSxZqugAEvAQBIDAIdACCpmK4AAIDkIdABAJIqVp6zRi8FAADNE4EOAJBUsZpcAgCAxCDQAQCSijgHAEDy1BvozOwZM8s3s6V1rB9tZvvMbGHw556IdePNbJWZ5ZrZHYksOAAgNVBBBwBA8sRTQzdV0vh6tvnEOTcs+HO/JJmZV9KjkiZIGiLpMjMbciiFBQAAAADsV2+gc87NlrT7II49XFKuc26dc65S0ouSJh3EcQAAKczFaHRJpR0AAImRqD50Z5jZYjN7z8yOCy7rKWlzxDZbgssAAEcQmlwCAJA8aQk4xgJJfZxzxWY2UdLrkgY29CBmNlnSZEnq06dPAooFAAAAAM3bIdfQOecKnXPFwdvvSko3s06S8iT1jti0V3BZXcd50jmX45zL6dy586EWCwBwmKCGDgCA5DnkQGdm3czMgreHB4+5S9JcSQPNrL+ZZUi6VNKbh/p4AIDUEqsPHROLAwCQGPU2uTSzFySNltTJzLZIuldSuiQ55x6XdLGkH5lZtaQySZe6wCyy1WZ2k6T3JXklPeOcW5aUZwEAOGzFqqGj0g4AgMSoN9A55y6rZ/1fJf21jnXvSnr34IoGAGgOCG8AACRPoka5BAAgJkcnOgAAkoZABwAAAAApikAHAEgq6ucAAEgeAh0AIKlocQkAQPIQ6AAAyUWgAwAgaQh0AICkijUPHQAASAwCHQAgqWhyCQBA8hDoAABJRZ4DACB5CHQAgKRiHjoAAJKHQAcASCriHAAAyUOgAwAAAIAURaADACQVLS4BAEgeAh0AIKmYtgAAgOQh0AEAkos8BwBA0hDoAABJRZ4DACB5CHQAgKSiDx0AAMlDoAMAJBV96AAASB4CHQAgqaihAwAgeQh0AICkIs8BAJA8BDoAAAAASFEEOgBAUjnaXAIAkDQEOgBAUpHnAABIHgIdAAAAAKQoAh0AIKmooQMAIHkIdACApIo1Dx0hDwCAxCDQAQCSivAGAEDyEOgAAEkVK8+ZNXoxAABoluoNdGb2jJnlm9nSOtZfYWaLzWyJmX1uZkMj1m0ILl9oZvMSWXAAQGqINW3Bqu1F2lFY3gSlAQCgeYmnhm6qpPEHWL9e0ijn3AmSHpD0ZI31Y5xzw5xzOQdXRABAczN9+Q6d/uCHTV0MAABSXlp9GzjnZptZvwOs/zzi7peSeh16sQAAzUVdXej89K0DAOCQJboP3bWS3ou47yTNMLP5Zjb5QDua2WQzm2dm8woKChJcLABAU2FQFAAAkqfeGrp4mdkYBQLdWRGLz3LO5ZlZF0kfmNlK59zsWPs7555UsLlmTk4O//0DQLPBn3QAAJIlITV0ZnaipKclTXLO7Qotd87lBX/nS3pN0vBEPB4AIHVQQwcAQPIccqAzsz6SXpV0pXNudcTyVmaWHbotaZykmCNlAgCaL/IcAADJU2+TSzN7QdJoSZ3MbIukeyWlS5Jz7nFJ90jqKOkxC0wsVB0c0bKrpNeCy9IkPe+cm5aE5wAAOIxRQwcAQPLEM8rlZfWsv07SdTGWr5M0tPYeAIAjiaOODgCApEn0KJcAAEShhg4AgOQh0AEAAABAiiLQAQCSiho6AACSh0AHAEgq+tABAJA8BDoAQFJRQwcAQPIQ6AAAAAAgRRHoAABJRQ0dAADJQ6ADACQVfegAAEgeAh0AIKmooQMAIHkIdACApCLPAQCQPAQ6AAAAAEhRBDoAQFI52lwCAJA0BDoAQFIR5wAASB4CHQAgqaigAwAgeQh0AIAkI9EBAJAsBDoAQFJRQwcAQPIQ6AAASUWeAwAgeQh0AICkooYOAIDkIdABAAAAQIoi0AEAkop56AAASB4CHQAgqYhzAAAkD4EOAJBUVNABAJA8BDoAQFI56ugAAEgaAh0AILnIcwAAJA2BDgCQVOQ5AACSh0AHAEgq+tABAJA8BDoAQFLRhw4AgOSpN9CZ2TNmlm9mS+tYb2b2iJnlmtliMzs5Yt14M1sVXHdHIgsOAAAAAEe6eGropkoaf4D1EyQNDP5MlvQ3STIzr6RHg+uHSLrMzIYcSmEBAKmHJpcAACRPvYHOOTdb0u4DbDJJ0rMu4EtJ7cysu6ThknKdc+ucc5WSXgxuCwA4gpDnAABInkT0oespaXPE/S3BZXUtj8nMJpvZPDObV1BQkIBiAQAOB44qOgAAkuawGRTFOfekcy7HOZfTuXPnpi4OACBBiHMAACRPWgKOkSepd8T9XsFl6XUsBwAcSSISnddj8vmJeAAAJEoiaujelHRVcLTL0yTtc85tkzRX0kAz629mGZIuDW4LADiCMG0BAADJU28NnZm9IGm0pE5mtkXSvQrUvsk597ikdyVNlJQrqVTSNcF11WZ2k6T3JXklPeOcW5aE5wAAOIxFdqGzpisGAADNUr2Bzjl3WT3rnaQb61j3rgKBDwBwhGJMFAAAkuewGRQFAAAAANAwBDoAQFJRQQcAQPIQ6AAASRU5D53RiQ4AgIQi0AEAkooaOgAAkodABwBIqqhRLqmiAwAgoQh0AIAk25/o0jwEOgAAEolABwBIKqYtAAAgeQh0AICkIs8BAJA8BDoAQFJRQwcAQPIQ6AAAAAAgRRHoAABJ5SIaXVJbBwBAYhHoAABJRYgDACB5CHQAgKQizwEAkDwEOgBAUjmq6AAASBoCHQAAAACkKAIdACCpIivobhh1dNMVBACAZohABwBIqshRLm8eO1DPXJ3ThKUBAKB5IdABAJKqZhc6kzVNQQAAaIYIdAAAAACQogh0AICkqjXIJRV0AAAkDIEOAJBU5DkAAJKHQAcASKqa89CZEekAAEgUAh0AIKmYVhwAgOQh0AEAkurOV5dE3ad+DgCAxCHQAQCSyuev2eSyiQoCAEAzRKADADQq5qEDACBxCHQAgEYVWUNXc8AUAADQMHEFOjMbb2arzCzXzO6Isf52M1sY/FlqZj4z6xBct8HMlgTXzUv0EwAApJbI+jk/eQ4AgEOSVt8GZuaV9Kik8yRtkTTXzN50zi0PbeOc+72k3we3v0jSLc653RGHGeOc25nQkgMAUlNEoisoqlCLDK/atkhvuvIAAJDC4qmhGy4p1zm3zjlXKelFSZMOsP1lkl5IROEAAM3baQ9+qFN/O6OpiwEAQMqKJ9D1lLQ54v6W4LJazKylpPGSXolY7CTNMLP5Zja5rgcxs8lmNs/M5hUUFMRRLABAKqo5KEpltb+JSgIAQOpL9KAoF0n6rEZzy7Occ8MkTZB0o5mdHWtH59yTzrkc51xO586dE1wsAMDhgmkLAABInHgCXZ6k3hH3ewWXxXKpajS3dM7lBX/nS3pNgSacAAAAAIBDFE+gmytpoJn1N7MMBULbmzU3MrO2kkZJeiNiWSszyw7dljRO0tJEFBwAkJqooAMAIHHqHeXSOVdtZjdJel+SV9IzzrllZnZDcP3jwU2/KWm6c64kYveukl6zQPuaNEnPO+emJfIJAABSi9HmEgCAhKk30EmSc+5dSe/WWPZ4jftTJU2tsWydpKGHVEIAQLNCngMAIHESPShKs1RUXqWX5m7W+p0l9W8MAAAAAI2EQBeHvaVV+sUrizV/456mLgoApDwq6AAASBwCXRzSvYGXqcrHXEkAcKhocgkAQOIQ6OKQ7g18+yDQAUAikOgAAEgUAl0c0tMCL1NlNYEOAA4VNXQAACQOgS4OGeEml66JSwIAAAAA+xHo4kAfOgBInFgVdD4/F8wAADgYBLo4eD0mjxHoAKChnKsd1GJNLM7fVwAADg6BLk7pXo8q+cIBAA0Sq+ItNNBUJP6+AgBwcAh0ccrwelRVTZMgAGiIWE0ph3Rvo1vGDopaVsWgUwAAHBQCXZzS0zw0CQKABvLX0eTyhtFHRS1buHlvYxWpTos279Wbi7Y2dTEAAGgQAl2c0r1GoAOABooV6CTJW6Mf3dTPNzRCaepWXuXTpEc/009f+Dpmvz8AAA5XBLo4+Z20YlthUxcDAFJKXaNXej3RgW70MV0aozgxOec0+O5p4ftNHS4BAGgIAl2cCooqtGjLPu0rrWrqogBAyliSty/m8pojXS7YuKcxihNTzTlGP8vd1UQlAQCg4Qh0DVRW5WvqIgBASthXVqXLn/oqrm3fWbJNReVNc8Gsojr673pdzUQBADgcEegaqNpPPzoAiEd5Ay+AlVY2zQWz8qrov+tMcg4ASCUEugaqZGhtAIhLQ/9ejvjfD7Vqe1GSSlO3msGTAbAAAKmEQNdA05Ztb+oiAEBKqNmUMR7n/2m2dpdUJqE0dauoETzXFZQ0+Bi7Syp11+tLVNZEtYwAgCMXga6BHpq2SiUV1U1dDAA47NVsynhK3/Yxt7t+VPScdCc/8IGW5u1rtOkDatbQbS8s118+XNOgYPnE7LV67stNuuPVxYdcnlmrCzRn/e5DPk5dnHN6YtZaFRRVSJLKKn1aGhy85o2FeVqz49BrSQubqD9kY3HOaebKfFVTm4tGtLagWPvKmvdnCweHQHcQjrv3fb21aKvyi8q1r6wq5peOfWVVKq6ols/v5A/2x/D5nZxzB/yS4k+xvhsH84XLOafc/KKEfVlzzkX9p+qPeM2l+PrxvP51nqZ+tl7b95WrtDJw3qp8fpVWJja8+yPeA7Gu5Ee+Jos279WWPaUxt3ljYZ5y84sP+FjVPn/U8cqrfKr2+cPPTZKKK6q1s7ii3nLHajrn87u4+xpV+fxRj1nz3Df1+76uizR+v0uJ/zwrq/1NMnda6EvtHz9YrXUFxeG/cSGRn73fX3yiXvnRGTGPc1yPtrWWXfiXT3XM3dM0e3WBdhVXHFJACP1NKKmo1g+mztWGnYEauKV5+3TjvxeoqLz2+f/DB6t1wSOf6JX5WzRzVX69j5GdmSZJemPh/onJ1+yI/++cz+80c1W+nHP6/jNzdMkTXyg3PzpYrdpepK17y+I6Xl027SrVm4u26sH3VurWlxZKkm7770Jd+JdPtbe0Uje/uFDn/XH2IT3GS/M268T7pickGB6uPl5VoGumztXjs9Yqv7C8wZ8/59xB1WAnU+T/pYXlVcovLG/iEh2cPSWVevC9Fc0ybJ/7h1n65qOfNXUxcBhKa+oCpKqfvPB1+LaZlOYxZaV5VVHtl8cTfWU6w+uR3zlV+53SvSa/kzLTPLLw/oFJy9M8ptIqn1pnRJyW4EZF5dXK8HqUle6RUygcSk6B33WpMTJ48JC1F8beLtbxopeWV/mU7vXITPKY7T+Ok5wC/0GEiucxk9+5qIEPQl+CYqnraVmNO6WVPvn8ThlpHqV5TJXVfqV7A7fLq32q8jm1SPfK75yy0r2BoCOp2hfYJyvdo53FgSvx9721vNbjZXijr3uEXnOPx5QZXOeLOAmR59XrMfmDZSut9Kmsyheef8vnd2qZ4ZXP75Tu9ajaHwhbXo9FvX+8HpPP75SdlSaPWVTAaJ2ZFn68Kr9fzknpXo+ccyqp9Ckr3VOrliQkcp3XY0r3Bo4UeioV1X61yvDK55zKq/zKzkwLn1MzU0W1r9brUFO138ls/2AXmWmecPO2DK9HmekeecxUXFGtrDRPrfdX4HXc/95xLnoEQq+ZFPgnn9/JYyYnyWOB909ltV8ZaTXK5mrfLa6oVqsMr6r8Lup8l1f55HNOrTLSaoXXmkWtWXKvx2RmdYfVWB+weLj9TyH0JbKsyqeMNI8yvJ79T+8Afxfi/eppFtjYH/wcm6T04OvZMt2rfWVVKgme2z9/uCa8X7o38NwjX8v+nVrVOv59Fw3R76at0kUndle6x/Sjfy+IWl9Z7ddVz8wJ3+/YKkO7atSadWqdqQyvKc3rUZrXtK6gRMP7dVBheZUGdc3Ww5cM1VXPzNGyrYWafPZR+mhlvj5ama/bzz9Gv39/lSTVGdq37SvXbf9dJEk6/aiOKq3y6fUfn6Ep01bqohN76Jhu2cHn61HblhlR+769eKtuev5rPXTxibokp3ddL3HYYzNz9YcPVusvl50UXjb24dla/+BEFZZVq23LdJ3/p0DQ2jDlAq3ZUaRHZ+bqx2MGaFDX7HqPH3L272eGb4ee99wNgSkjajY9DSkoqtBnuTv1jZN6xly/rqBYHVplqGVGmqp8fs1YvkOStLagRANrlK20slqbdpdqcLc2cZc50WauzNfHq/J12Yg+6tGuhdpkpUsKXNiZtbpAE0/oXue+S/P26bWv8zSoa2tJ0kcr8/V/01frnguH6Hun9dX9by/TT88dqC7ZWQcsw+Oz1ul301Zq8X3jwo/f1J77cqPufmOZ5vzqXI3/0yfaXVKpDVMuSPjjlFRU6+X5W3TV6X1j/s0/kFXbi/TOkm26ZezAOvf99VvL9PrCrTqlT3uNO65bIop80KYv267J/5qvOb88V13aHPg9Ea91OxveJDyVbNlTql7tWzZ1MVIOgS5Oz/9whB58d6XuvWiIVu8olpPTpl2l2l1SqTYt0pWR5lFZpU9Z6V75/H61bZGuNfnFqqjyq0/HlvIGA195tS9YcxI4biicFVdUq01WupxcOHCFopBzgf8E07ye8BekNE8gPJkFt471dy3Gt7ZYX+RiXVmMFRJj7RuaG9i5/c9FCnwRNAXLGNzW7wLbez2mz9bu1Kn9OsQMl5Fq/r2OLFfo9fH5ndbvLFHn1pnKzkpTy8w0lVX65DFTZrpH6R5TaWUgSJWFAmiwPJU+n8qr/NpXVqWsdK96t2+h7Kx0lVf5tLO4QmWVPnVtW/uPsCkQ4iqr/TKZPBYoa2T5/E7y+f3hwJ7u9WhXSaU6t87U3tJKbdlbpuN7tFW6NxDYyqp8apnhVWW1X+t2lmhtfrGG9m6nNlnpgdCU5lGlz6+te8tUWe3XKX3bq6TCF34tQu+N6mDYr/YHHnP9zhK1ykzTmh1F6tAqQwO6tA5v6/WY1haU6OgurcJlD72fKqv98vudvB6Piiuq1CozECgjz0PgAoVTlc+F10Wen2qfk9+5cNjwO6ddxZXq3CZTPp+Tz+2vLcxM88q56HMeCnDOOXk8FrhoEHyOaZ7AxZFQwPN6Aq9zWaVPrYIXCtK9puoYgarm+27znlJ1b5slj1nUhQnnAl9627ZIl9ez/4JGzc9M9PsyIFRb5fXUDrsu7kgVW+izFbgduJoeuKAReKz962qfk9Cy+r5HhV770OsRzHbh81VS4VNheZVmrNgh56QLT+yunu1bqKLKL6/HAheoKn36LHenfjxmgHL6daj1GFef2V9Xn9lfkjThhO56/2dnKzsrTWle05Y9ZVqwcY/eXrxNWeketcxIU1a6R8u3FmrDrv0117FqmOdsCDRXXLm9SG8u2l9jFgpwNW9/mrszfPtXE4/Vb99dUeuYX6wLzE334Hsr9eTsdXpi1jr16dBSTk6nH9VRL83bEt72B1Pn6qOVgVq9X7y8WKcf1VFvLd6qY7u30VuLtqq8yqfHrjhFUqC54+VPf6lleYWB49d47I9W5uvaf87Tv64dHnFunK7/13yt21mi1xdu1dr/nVhronZJKiqvUkFRhe5/e7muGNFXY4+NPXl76P0c+dgX/+1zPXfdCKV7Pbrun3O1aMs+nT2oszq02h9cfX6nIfdMU0W1XwO7tFan1pn6Yt0unTM48DhpHtPNL36tNxZu1TNX52jMMV300xe+1owV+Vr5wHhlpXu1ZU+pzvrdTP3xu0P1zZN67X+91+7Slj2l+k6NMBx67iOO6qhrz+of8/lEys0vUouMNPVs1yK87JqpcyVJ//xiowZ1ba3pt4ySFDhX7yzZphm3nq0BXWKH5G/97XNVVvt130VDJEkLNu2VJN3/9nJlpXv13JebtLe0Sn/87jCZpDSvRzOW71B2VprmrN+tn5w7UJL0l48CF0CWbNmnMwd0qrP8BUUVyi8qV7+OrfTPLzZo8sijlFbHBbRD9cqCPEnS5t1lB2xuXOXzh5+bJP3w2Xlasa1Qn/6/c+J6nCnvrdS/vtyoXu1b6Nxju9a5XVF5lVqke6Oe7/f+/pUKiip07Vn9w60C2rRI18LNe8MXTkIXEGP9lc0vLD9gsCosr5Lf79Q/OR+2AAAed0lEQVQueIGmoKhC7VumH/Rr/u+vNkmSlm7dp3MOMtBV+/zaXVKZsEAYEvpecjiZsXyHrnt2nsYN6arrRh6l4f1r/79xqP7+6Xq9Mn+L3r15ZMKP3ZQIdHE64+hOeusnZ0lSzC8mAIBDE6rxkqQu2Vk6uU97XTfyqAPsEbjav6e0UiUVPm3eXar3l21XbkGxvg5+0W6Iy4b31tVn9osZ6EKenL0ufHvT7kCw3Lx7S9Q2oTAXMvKhmarplflbtHFXiR75KDdq+dZ90c3cZqwIHOuW/yyKWhY5J2po/r7Nu8t0Qq/9zVdP+c2McHPpj1cV1CrD4i37tGFnSfiCxOsRzUXnbdyjVxfk6ZevLQkvq6z2Kze/SGMfnq0Zt47SJ2sKwrV6a/KLtSbYDDz0/NfvLAk3Qf3B1Hma8q0TwpO2l1RUy++c7nhlSfj5XXBCj3CN+mVPfSlJ6pydKeekQd2y5fc7tc5M0/TlOzR9+Q5dc0Y/eWoE2c27S/XE7LW6Y8Kxeu3rPN39+lJJqrOmafWOYm3cVaK+HVtpVbCJ6NK8Qs3fuEeX5PSW3ykqLIdez7wYTV9Dr1W1z2ngr96TJP3tipOjap6vOr2f5m3cHQ4dVzz9lU7t115Xnd5P5x/XTX+dmatrzuin9sHgfO4fPlZhebV+cGZ/PfPZej00bZVm3T5afTvWrvEO+XrTHi3YtDeuwDvs/uka3C1bL04+PXyB9kBNFXeXVOrkBz5Q7w4t9MkvzpFzTh8Ea2QLy6tUXF6tu15fqv/7ztCo8C9Jn+Xu1LDe7cI1w799Z4WW5O3Tz8YOivlYJ9w3XRcN7RFVax1qxv2Pz9brTzPWRG1fWFala8/qH77IF7rI+OKcTYFavfMG6VuPfa57LhyiH9R4bYrKq3TCfdPD9zdMuUDFFdU69bczdErf9hrQubUe/NYJtd5v9Qm1fCmuOPjmtb9+a7n+9eVGLb5v3AG3276vXC3SvWrbsv4a3xXbCjXhz5/o6atydHSX1urQMiOu/WraU1KpF+du1vVnHxXztQnVUM791Vh1zs6s93hLgn15Q5/xhtYQh1qNxbrAFfLA27VbYjUHBDoAQMpqlZkWrpE9plu2xg7Zf8XfOae1BSVqmeHV/3tlsbKz0vTukrpHKv7F+YOV7vVo2a/P1+/fX6Wpn2/QhSd213dP7a0r/z6nzv0ORqgpZ31emBO4wh9ZE/nDZ+dFbTPs/g/CtztnZ2rkwE56NVjbUp/xf55dZ7PsyDAnSac9+GH49juLt9Xbv7RmML7j1f3HO+U3M2ptv6OwXL07RDe1uvofc+s8/s/+s1APXXyiXv86T+t3leiO8YPD4XnV9qJwU1JJGvird/XApON16fA+tY4z5v8+1q8nHR/ul/yz/wT6Fn6yZqfeXrxN6x+cqMc+XhvVCuGpT9bXWa7IZuE1mxEPvX96zc01d8OeqLJW+/z6xfjBWrW9SIXB/p17S/fXmI36/cd6/Hsn68nZ63ThiT00/vhu6hFRA/nNxz6XJE08oZu6t20hv9+Fv2wv3rJXPdq1UKfWmVqyZZ/2llbpy3WBGu1QC4TFW/bV+dxOfiDwXtu8OxBoX5izObzuxIhA9OwXG6KCWt7eMl3x9FeSpPOCn9F1O0v0pxlr9LOxg/Ty/C3aXVKhXSWV+n/nDw5fKHhr0Vb97tsnaG1+iXaWVIT7u9YMc5L0m3dWqFvbrHBLodB3+tD77pM1gZr45+dsqhXoQgMERSoMvr/nb9yj+Rv36KZzBkS9PyuqfdpTUqVubbP023eWa9u+cl1zZj+d3Ke9nvtqky48oXu4BuynL3yt/xnaI7yvz++0p7RSnVpHh5xX5m/RcT3bRDVJDo2uvq90/+dt5qp89WzXQoO6ZuujlTv06oI8vb14m9q3TNfX98QOfnl7y/TVul361sm9NDfYimHmqnxd9+w8dW2TqdGDuugHZ/XXoK6t5XeBVhmzVhcop197ZdfRLPhXry/Ru0u266Q+7XTaUR1rrX/2i42SpJXbC9U5u3PMY4Ss2l6kHYfYb3Pw3dP0zZN66o/fHXZIx0lFBDoAQLNkZhrQJdDX6V/XjpAkPTFrrTbvKdWAzq319uJt6tm+RbgWKVQr0iozTSf1aaepn0vZWekaObCzHvr2ifrFKwcewfLn4wbp/6avTuIzql9BUUXcYU6qPRJpvF6Ys0njj09s/6SRD83Uuv+dqGc+qzssRXpz0VYN6NJaD38QeM27RzRJiwxIklTlc7rj1SUxA53fKVyTF+ntxdskSU/MXhfVRLc+04M1VgfrsY/Xavm2wqha1Ve/jj6nNzwXCIoLNu3V/W8v17y7xqpNVnpUn+HTH/xIp/Rtr/kb96h3hxYa2qtd+DmNPbarZq/ef/yPV+Vre7B2uMq//z2xtqBYfTu01H/mbdZTEbXTkvT52p169osNMZ+Dx0zrCor15brd2ltWqT9EfC4+qPH69Lvjnaj75x/XTR2Dn0WPSfe+sUz/nR9dC16Xl+dvUUXwPf3Jmp0a2rtdrW0iBxTbtq9Mpz/4kW6JUUtYczCwbz72uebdNTZ8/6cvfK33l+3QE1eeEg74by/epvduHqm7X1+qj1fm1+rD/dyXG9WxVYb+OjNXy7YWasHd54VrMp+YtVYPvrdSLdK9WnzfOD3y4Rr98Oyjwg3nIwdvuiZ4oeOVH52hH0zdf4FnT2ntiyzLtxZq4iOfhO+fNaBT+DXKTPNKknYUVug/8zZr+vLtGjWos+Zu2KOcfu31xsKt+uk5A3TruGPC+6/YVqgf/3uBXvvxGdoVHH+guLxaZZU+rd5RpEnBQVsWRQTLyG4JxRXVap2ZprUFxfruE19oaK92+vvVp4b7CMdjad4+HdW5lVqkB8pvZuGLHq99nRcOdHtKKnXSAx/o39eN0JkDOkUNRPTw9FU6e1DnZtPqjkAHADhiXD/q6PDtq8/sr4pqn6r9TreMHRi13YTju2vZ2YW6cfQASdIlp/YOB7q7LjhWv3mndrPMIT0CV9U7tc7Uqf3a672ltWsDu7bJ1JRvn6iPV+brn8Gr16loe2G5pn6+IeHHHfHghzFrS+oSCnNS7EGtavrTjIYH7invrWzwPocqVhPZA8kJ1ni+/7Ozo5bP3xgItpt3l4Vr1SRpxoroUBVZE/rQtP3h9dw/zFKrDG948KNIlz/1VZ3l8Zg08ZFPDuqCwS3/WaiNwX6yfqe4w5wU/bpN/XxDne/R3SWVat8yXdOCn9E/xnhflNQY5XpncYX+9vFa/Wj00Vq2dZ/eXxZ4Da//1/yo7UJTjuTtLVP3iD74ldV+3VXjwsFD01ZqyrdP1NOfrNODwfdZWZUv3GT3LxFNsnMLao9s/eTstbWWzV5doC5tMvXw9NUafUyXWqM4v7Fwa7j2vGbg3FNaFW56nbcw8H555KNcnXts13A4fnRmrtbvLNGs1QXhoHZdjVYDkvTZ2p21+mp/nrtTlz8d/b75cGW+nvk09kWc/KLyWgMMbdpVqgv/8qkk6fiebbR9X4Xm3TVWW/fWrt1buCXQ9P6Kp7/ShikXhJt4h57XIx/l6s2bztTCzXt17rFdo/raphqLZ6hdMxsv6c+SvJKeds5NqbF+tKQ3JIXOyKvOufvj2TeWnJwcN29e7TcHAABNZdwfZ2n1jmJtmHJBrVoFSXrqqhz98Nl5OndwF/396lNVVF4lJ+nJWeu0cnuhZqzI19GdW+nD20bLOaf+d75b52N5PaYJx3cL16jE8shlJ+mnESMu1+Wtm87SRX/9tNbyOyYMrjes3DlhcPiLZjy+MaxHVF88IBXdOOZoVVb7Yzat7d2hRVQ4rkv3tlnaFtEn9srT+upfX9a+iPPZHefozCkfHVqBG8HTV+Vo7JCuuvWlhXG1Anj08pP14txN+mTNTnVvm6V3fzpS5/1xVnhU8XjM/PloZaV79OGKfH3vtL7aUViuHYXl+p+/Rk/dsP7BiTr+3vfDFx7+8J2hqvb71bFVZjhs/vnSYfrVa0tVXMc0Rc9dO0JnDax7gKKmYmbznXM59W1Xbw2dmXklPSrpPElbJM01szedczUvhX3inLvwIPcFAOCw9vqNZ4YHs5jzy3PVIsOrrHSvLv7b51q6tXB/351g551Qv5Ofn3+MKqv9uvofc3TbuEDTLjPTOz89Sz3attCukgqNfTjQ3Ojx752sG55boMw0j/586Um6YkRfbS8s09eb9ob7owT2l/5naA/d+cpilVT6NG5IV5kpXGswpHsbtczw6run9tbRXWIPoHH92UfVG+iuH3W0Jp99lKYt3a5zju2ih6ev1rRl28M1KDVNOqmnqv3ugEFUkjq0ygiPpPjxz0frzx+u0Wtf1/0l8fzjumrV9qKoEU4PJ4vuHae7Xl+qtxYlN8wSmBvHozNr13yFxBPmJEWFOUkxw5yklAhzUqAW7p4Lh8Rdg75hV0m43+K2feW6581lDQpzUmCApdAgJve/vVyV1X6NG1J7ZNQX526OqkWO1Uf5rUXb6gxzktSrferWzknxTSw+XFKuc26dc65S0ouSJsV5/EPZFwCAw0bLjLTwIAZd2mQpOytd6V6PXvvxmVrzmwnq0S7QNGhYjH47GWkePf/D03RK3/39NY7r0VbtW2VoQJdsffzz0Zp9+xiNPiYw5P/w/h3k9ZhOP7qjvnlSL90Q0VRUkq4YEegLdm1wFNBbxw3SE1fm6PnrAn0FLxzaXS//6Ax9J6e3soL9ZCSpX8eWGh7sM2Jmmn37GH0rYn65scd21R0TBmvlA+O17n8nhrebcEJ3ZaZ5defEY/XRbaM1MuJK9vWjAmU4qnMrjRzQSbeeFwitkc2Xag4//tRVp4Rv92rfQn/87jB9dNuomK+7JLVtka6Pbhutt39ylu6fdJweiRj5MOSuC46tc//6DOvdTm/ceGbUsstH9FHLDG8de+zfb8Lx3dS2Rbp+9+0TwqMaRnpx8mk6tnugOe6Ht43SlG+dIEn6/cUnNricD3zj+AbvE8uEBvR/PKYB8xyi6RzK+z9e97+9PBzS6lOz3+nBXOyIHJEy1KcxVh/VO19dUmtZTTWbGdfUM8UDXb1NLs3sYknjnXPXBe9fKWmEc+6miG1GS3pVgVq4PEk/d84ti2ffWGhyCQBIRSu2FeqYrtkNHt685jH6dmyplhnRjWiWbd2nLXvKNKJ/B7XOTFOa1yOf32nl9kId12P/dAWV1f7w5O4hX63bpQFdWqtj60yVVfpUVF4VNa/VruIKmVmtoebr4vc7HfXLd3XBid316OUnR63bWVyhnN/M0B0TBmvi8d21ZU+pzhjQKdzMtFWGV8vuH6/3lmzT9sJyXXPm/hEH+93xjlqke9WtbZbWBydQPmtAJz32vZNrTcD933mbdfvLgX6NV57WV/dPOk5rC4p120uLtLO4Uk9dlaMhPdrEbB4b8vNxg2RmunHMgPDr8PWmvTpncBd5PKZqn1/vL9uhO15ZrKKKav183CB9smanvlq/WzNuHRUedCfkoWkr9djH0bU7sYZe31NSqRYZXg2+e5ok6SfnDIjqLxXSqXWGfn/xUD32ca5OP7qTbhk7UA+8vaLWwDH3TzpO97yxLOoxaz7vnu1aKG9vWXgy80se/0KXDu+tW1/aX5vRr2PLqFrQS3J66aGLh2rZ1n3ymGlJ3j794uUDDw40aViP8EBDifLklacozWtRA4CE1HzusWR4A/O4StJ3TunVoH55qeKWsYNi9gVE/cYe20VPf//Upi5GTAlrchmnBZL6OOeKzWyipNclDaxnnyhmNlnSZEnq06f2KFQAABzuQjUxyTjGcT3aRgU3KdDXruaymgMdSNKIiCHFW2R41aJGzVPH1vXPERXJ4zEtumdcreNIgUFhlv76fLXK8MrM1KdjYKh3M9M/rjlVR3cKhKAJJ3Svte9L15+uPh1aqlvbLL0wZ5P++lGu/nXt8KhwGvKdnN76Tk5vVfn8SvNYcFTTbL1x01kxy/zfG05Xl+xMlVb6ZCbtLKqs1WemY+vMqKkv0rweXXBid40d0kWvf52n75zSWz88+yiVVfrCk09HuvL0vvo0d6eeuipH2VlpquuaeWhE1Q9vG6XszDR1aZMVDnSRYWzeXedJksYM3j8p/D0XDakV6Pp0aKkbRh2tx2et1YgataF1zeX10g2nS5JaZ6ZpcnBgj49vHxMVBK8Y0VeSwu+xY7u30bdP7qWSymo9OjNXT8wKjHw5cmCncM3Npaf2aVCgu2nMAM1YsUMrtxdFLY/s4znuuG76ZE1gwJPzhnRVj7ZZ4UGFDlQvcWz3Nrokp5dM+wfNufL0vtpZXKGZNQaeufncgfrzh7WnQwg5d3AXfRgxx2TPdi00vH8HTRrW44DTa9T050uH6eYXF8a9fbyO79lGZgd+PSLdfv4xDRq9tTlL8xxeE6wfjHhq6E6XdJ9z7vzg/TslyTn34AH22SApR4FQ16B9JWroAABAYry6YIsKiiqiRjg9HF3+1Jf6fO0ubZhygb7etEedWmfWmpcv5NGZuRrUNVvzNu7WE7PW6aPbRumozq1VUFSh7Kw0ZaV79emanary+aPCYF2qfX6VV/vVOjNNu0sq5TWrd6Jp55zy9papRbpXaV6Phv56un45cbAmn3205qzfrS7ZmXpnyTZt3Vumf3+1qc7j/OYbx+uCE7pr9Y4itW2ZLo+ZNu4q1XlDuureN5aqS5ss3ThmgJxzeu7Ljfr2Kb3UMiNNVT6/vGYqrfLp1v8s1L3/c5z+O2+zFmzaq0tP7a38wnJdHaz9fXvxVt30fGAAoddvPFNes6iBgl778Rk6qU97fbVulyp9fi3J2xce7bNH2yxt3Veui0/ppZcjavbW/HZCeJ65WasLdGy3bA3/38BcjaHa0Ld/clZ4REYp0Dz5zgnH6qnZ62rN0xjy3s0jdUzXbOX8doZ2l1Rq9W8mKCPNo5Punx41LcHQ3u20aHNgFMfZt49Rn44ttaekUv83fZU+Wplfqw9fpNvOG6SfnDtQg+9+74AjkT7/wxEHHM20IQZ3y64V2mO5bHif8PybiRLZZzeWkQM7hae2OdzEW0MXT6BLk7Ra0rkKNKecK+ly59yyiG26SdrhnHNmNlzSy5L6KjCy5QH3jYVABwAAjiQ+v5PP72LWsNbFOaftheXq3rbp+/9E1pTWVFbp08vzN6tHuxY6c0CncFPT+ycdpytG9JX3EJoox+OLtbt02VNfSgoMYNO2RSCsnvHghxrULVtTrxlea5/r/jlXM1bk6/HvnaIbnpuvByYdp7trNGut6cH3VujoTq312Me52rCrVDNuHaWxD8+SJA3q2lrTb9nfT/T4e99XRbVPL04+TX/7eK1mrMjXH74zVN8+pZckafPuUs3fuEffCPZx3VdapV+9vkRvL96m288/Rtec2U/PfLpeOf06xJzUu66mxiP6d9B/rj895jZ9O7bUB7eM0qC7AtMmLLpnnBbn7dWX63bVGigm1Ez45nMH6kejjw6fU0m1agovOLG79pZW6rPcXZKkb5/cS68siN3s9bLhvfXCnM366bkD9cgBakxjGdwtW//8wXCNCAZrSfrlxMHaUVihv3+6Xucf1zU8cFRI1zaZ+vv3T9XxPdvWPNxhIWFNLp1z1WZ2k6T3FQhozwT7x90QXP+4pIsl/cjMqiWVSbrUBZJizH0P+lkBAAA0Q16PNTjYmNlhEeYkhWurYmmR4dWVp/cL379iRB8N7dVOl5zauxFKFhiwR5JuGHV0OMxJ0ud3nlvnPn+9/GTtKqlUj7ZZenHyaRrRv4P2lVVp/sY9evzKU2Luc+eEwMAkj8/aH342TLlAn6/dWWtwmdAk5VnpXj39/dqTW/fu0DKqhrZty3TdOfFYrdpepG+d3FMtM9J00zn192765BdjNPKhmeH7t5xXexL1kP/ecHrUBYVWmV6NHNhZQ7q30aMz1+rGMUfr+lFHa2dRRTgYdW2Tpax0r97/2dlqmeHVyIdmavLZR6lz60xt31euFdsL9ZdLT9LOkgr9ecYaDevdTt/J6a0/XDJUg371nip9fm2YcoH+9eVGzVm/WxNP6K4X5mzWxSf3Uu/2LXT7y4v15JWnKN3r0TVTA01bVz4wPhwgR/TvoPYtM9Qyw6u7Lxyi9q0y9OwPhuuqZ+ZICkxUX1bl0ysLtuiei46Tz79/gJRJw3roT98dFvMiRKqJax66xkYNHQAAABJly55SdWuTpbQDBM9EeX/Zdt320iLN/dXYmP1MG0Oo9m3DlAt0zT/m6Lun9tH4GqObPvzB6nAt2E1jBujn5x9Ta9+QXcUVatcyI3zRoaLapxfnbNb3TouuYa32+eWto6a2pg07S7R5T6lGDuwc13N6c9FWFZVX6fLhfcLzeIaay9b1/BfcfV7UYE9vLMwL92Gsq3/p4aSxB0UBAAAADku92sfuj5gM5x/XTef/Ov6pIZLtHzGalErSrecN0k/OGaAnZq3VdcEpUOpSc+CkzDSvvn9Gv1rbNSQw9+vUSv06xZ4nM5b/Gdoj6v5FQ3vEDHOSlOYxVfudWmdGR51Jw3omZVCapkagAwAAAJqR337zeFVV1z3gSUi611Or6eaALq2Vm1+crKIlxOrfTFDaAZoov37jmfpg+Y6YfVKfuionap7M5oAmlwAAAAAkSeVVvpi1W2h8NLkEAAAA0CBZ6U3T7w8HL/Vn0gMAAACAIxSBDgAAAABSFIEOAAAAAFIUgQ4AAAAAUhSBDgAAAABSFIEOAAAAAFIUgQ4AAAAAUhSBDgAAAABSFIEOAAAAAFIUgQ4AAAAAUpQ555q6DLWYWYGkjU1djhg6SdrZ1IXAIeM8Ng+cx+aB89h8cC6bB85j88B5bB76Ouc617fRYRnoDldmNs85l9PU5cCh4Tw2D5zH5oHz2HxwLpsHzmPzwHk8stDkEgAAAABSFIEOAAAAAFIUga5hnmzqAiAhOI/NA+exeeA8Nh+cy+aB89g8cB6PIPShAwAAAIAURQ0dAAAAAKQoAh0AAAAApCgCXRzMbLyZrTKzXDO7o6nLgwMzsw1mtsTMFprZvOCyDmb2gZmtCf5uH7H9ncFzu8rMzm+6ksPMnjGzfDNbGrGswefOzE4JvgdyzewRM7PGfi5HsjrO431mlhf8XC40s4kR6ziPhyEz621mM81suZktM7Obg8v5TKaQA5xHPpMpxMyyzGyOmS0ysxVmNiW4nM8jJOccPwf4keSVtFbSUZIyJC2SNKSpy8XPAc/ZBkmdaix7SNIdwdt3SPpd8PaQ4DnNlNQ/eK69Tf0cjtQfSWdLOlnS0kM5d5LmSDpNkkl6T9KEpn5uR9JPHefxPkk/j7Et5/Ew/ZHUXdLJwdvZklYHzxefyRT6OcB55DOZQj/B17x18Ha6pK8kjeTzyI9zjhq6OAyXlOucW+ecq5T0oqRJTVwmNNwkSf8M3v6npG9ELH/ROVfhnFsvKVeBc44m4JybLWl3jcUNOndm1l1SG+fcly7wP9ezEfugEdRxHuvCeTxMOee2OecWBG8XSVohqaf4TKaUA5zHunAeD0MuoDh4N12BCoc94vMI0eQyHj0lbY64v0UH/kOIpuckzTCz+WY2Obisq3NuW/D2dkldg7c5v4e/hp67nsHbNZej6f3EzBYHm2SGmgVxHlOAmfWTdJICtQJ8JlNUjfMo8ZlMKWbmNbOFkvIlfeycWyo+jxCBDs3TWc65YZImSLrRzM6OXBm8IsV8HSmIc5fS/qZA0/VhkrZJ+kPTFgfxMrPWkl6R9DPnXGHkOj6TqSPGeeQzmWKcc77g95tekkaa2Zga6/k8HqEIdPXLk9Q74n6v4DIcppxzecHf+ZJeU6AJ5Y5gMwMFf+cHN+f8Hv4aeu7ygrdrLkcTcs7tCH4Z8Ut6SvubNnMeD2Nmlq5ACPi3c+7V4GI+kykm1nnkM5m6nHN7Jb0jKUd8HiECXTzmShpoZv3NLEPSpZLebOIyoQ5m1srMskO3JY2TtFSBc/b94Gbfl/RG8Pabki41s0wz6y9poAKdhXH4aNC5CzY9KTSz04Ijd10VsQ+aSOgLR9A3FfhcSpzHw1bwdf+7pBXOuYcjVvGZTCF1nUc+k6nFzDqbWbvg7RaSzpO0UHweISmtqQtwuHPOVZvZTZLeV6AD6jPOuWVNXCzUrauk14Ij8KZJet45N83M5kp6ycyulbRR0iWS5JxbZmYvSVouqVrSjc45X9MUHWb2gqTRkjqZ2RZJ90qaooafux9LmiqphQIjeL3XiE/jiFfHeRxtZsMUaA60QdL1EufxMHempCslLQn225GkX4rPZKqp6zxexmcypXSX9E8z8yhQIfOcc+4DM1sgPo9HPAs0twUAAAAApBqaXAIAAABAiiLQAQAAAECKItABAAAAQIoi0AEAAABAiiLQAQAAAECKItABAAAAQIoi0AEAAABAivr/0oRTs/P58jYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 15, 5\n",
    "\n",
    "\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(labels_train, predictions_train))\n",
    "print(accuracy_score(labels_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(labels_train, predictions_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(labels_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(labels_test[::2], get_final_predictions(probabilities_test, threshold=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(probabilities_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
